{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from tools import brikasutils as bu\n",
    "from tools import shared_utils as utils\n",
    "from tools.shared_utils import systemMsg, userMsg, assistantMsg\n",
    "from tools import survey, persona\n",
    "[importlib.reload(m) for m in [persona, survey, utils, bu]]\n",
    "\n",
    "import ollama, os, re, time, json\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "from openai import OpenAI\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def see_if_column_valid(column_name, df, msg=\"Verification failed for\"):\n",
    "    dff = df[df[column_name].isna()]\n",
    "    dfff = dff.groupby(\"sim_signature\").apply(lambda x: x[x['run_number'] == 1], include_groups=False)\n",
    "    print(f\"{msg}: {len(dff)} ({len(dfff)} unique)\")\n",
    "    return dfff\n",
    "\n",
    "MOST_IMPORTANT_COLUMNS = ['sim_signature', 'run_number', \"model\", \"survey_type\", \"base_sim_signature\", \"SUBJECT\", 'CTX_limit', \"retrieval method\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index all simulation files\n",
    "SIMULATIONS_DIR = \"analysis/sims-final-2\"\n",
    "\n",
    "sim_runs = []\n",
    "for root, dirs, files in os.walk(SIMULATIONS_DIR):\n",
    "    for file in files:\n",
    "        if file.split(\".\")[1] != \"json\":\n",
    "            print(f\"Invalid file (all must be json) {sim_run['path']}\")\n",
    "\n",
    "        sim_run = {}\n",
    "        sim_run[\"SIMULATION_ID\"] = file.split(\".\")[0]\n",
    "        sim_run[\"path\"] = os.path.join(root, file)\n",
    "        with open(sim_run[\"path\"], 'r') as f:\n",
    "            sim = json.load(f)\n",
    "        sim_run.update(sim[\"info\"][\"info\"])\n",
    "        sim_run.update(sim[\"info\"][\"settings\"])\n",
    "        sim_runs.append(sim_run)\n",
    "\n",
    "df = pd.DataFrame(sim_runs)\n",
    "df = df.dropna(axis=1, how='all')\n",
    "print(f\"Loaded {len(df)} simulation files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infer/Get Needed Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_survey_type(row):\n",
    "    if \"survey_type\" in row and not pd.isna(row[\"survey_type\"]):\n",
    "        if row[\"survey_type\"] == \"KanoSurvey\":\n",
    "            return \"KanoSurvey\"\n",
    "        elif row[\"survey_type\"] == \"PersonalitySurvey\":\n",
    "            return \"PersonalitySurvey\"\n",
    "        else:\n",
    "            print(\"Unknown survey type\" + row[\"survey_type\"])\n",
    "\n",
    "    if \"prompt_count\" in row and not pd.isna(row[\"prompt_count\"]):\n",
    "        if row[\"prompt_count\"] == 50:\n",
    "            return \"PersonalitySurvey\"\n",
    "        elif row[\"prompt_count\"] == 40:\n",
    "            return \"KanoSurvey\"\n",
    "        else:\n",
    "            print(\"Unknown prompt count\" + row[\"prompt_count\"])\n",
    "\n",
    "    return None\n",
    "\n",
    "df[\"survey_type\"] = df.apply(infer_survey_type, axis=1) \n",
    "df[\"survey_type\"].value_counts()\n",
    "\n",
    "# extract_run_number\n",
    "def extract_run_number(sim_id):\n",
    "    try:\n",
    "        parts = sim_id.rsplit('_', 1)  # Attempt to split by the last underscore\n",
    "        if len(parts) == 2:  # Check if the split was successful\n",
    "            return pd.Series([parts[0], int(parts[-1])])\n",
    "        else:\n",
    "            print(f\"Error while processing {sim_id}\")\n",
    "            return pd.Series([pd.NA, pd.NA])  # Return None for last_number if split fails\n",
    "         \n",
    "    except Exception as e:  # Generic exception handling\n",
    "        print(f\"Error while processing {sim_id}\")\n",
    "        return pd.Series([pd.NA, pd.NA])\n",
    "\n",
    "df[['sim_signature', 'run_number']] = df['SIMULATION_ID'].apply(extract_run_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# infer_if_simulation_is_base\n",
    "def infer_if_simulation_is_base(row):\n",
    "    if row[\"sim_signature\"][:4] == \"base\":\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "df[\"is_base\"] = df.apply(infer_if_simulation_is_base, axis=1)\n",
    "\n",
    "# Below: Vanity Print\n",
    "dff = df[df[\"is_base\"] == True]\n",
    "dff = dff.sort_values(by=['sim_signature', 'run_number'])\n",
    "dff = dff.dropna(axis=1, how='all')\n",
    "dfff = dff.groupby(\"sim_signature\").apply(lambda x: x[x['run_number'] == 1], include_groups=False)\n",
    "print(f\"Found {len(dff)} ({len(dfff)} unique) base simulations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map simulations to their base\n",
    "def map_simulation_to_base(row):\n",
    "    if row[\"is_base\"] == True:\n",
    "        return \"(base)\"\n",
    "    if row[\"survey_type\"] == \"KanoSurvey\" and row[\"model\"] == \"gpt-3.5-turbo\":\n",
    "        return \"base_kano_v2_gpt35\"\n",
    "\n",
    "    if row[\"survey_type\"] == \"PersonalitySurvey\" and row[\"model\"] == \"gpt-3.5-turbo\":\n",
    "        return \"base_personality_v2_gpt35\"\n",
    "\n",
    "    if row[\"survey_type\"] == \"KanoSurvey\" and row[\"model\"] == \"llama3-70b\":\n",
    "        return \"base-kano-29_llama3-70b_V7\"\n",
    "\n",
    "    if row[\"survey_type\"] == \"PersonalitySurvey\" and row[\"model\"] == \"llama3-70b\":\n",
    "        return \"base-pers-29_llama3-70b_V7\"\n",
    "    \n",
    "    if row[\"survey_type\"] == \"KanoSurvey\" and row[\"model\"] == \"llama3-8b\":\n",
    "        return \"base-kano-29_llama3-8b_V7\"\n",
    "\n",
    "    if row[\"survey_type\"] == \"PersonalitySurvey\" and row[\"model\"] == \"llama3-8b\":\n",
    "        return \"base-pers-29_llama3-8b_V7\"\n",
    "    \n",
    "    if row[\"survey_type\"] == \"KanoSurvey\" and row[\"model\"] == \"mixtral-8x22b\":\n",
    "        return \"base-kano-29_mixtral-8x22b_V7\"\n",
    "\n",
    "    if row[\"survey_type\"] == \"PersonalitySurvey\" and row[\"model\"] == \"mixtral-8x22b\":\n",
    "        return \"base-pers-29_mixtral-8x22b_V7\"\n",
    "    \n",
    "    return pd.NA\n",
    "    \n",
    "df[\"base_sim_signature\"] = df.apply(map_simulation_to_base, axis=1)\n",
    "dff = see_if_column_valid(\"base_sim_signature\", df, \"Missing mappings\")\n",
    "if len(dff) == 0:\n",
    "    print(\"All mappings are valid\")\n",
    "else:\n",
    "    print(\"Not all mappings are valid. See the missing mappings below\")\n",
    "    display(dff)\n",
    "\n",
    "def infer_subject(row):\n",
    "    if row[\"is_base\"]:\n",
    "        return \"(base)\"\n",
    "    if \"SUBJECT\" in row and pd.notna(row[\"SUBJECT\"]):\n",
    "        if row[\"SUBJECT\"] == \"airidas\" or row[\"SUBJECT\"] == \"Airidas\" or row[\"SUBJECT\"] == \"airi\":\n",
    "            return \"airidas\"\n",
    "        if row[\"SUBJECT\"] == \"elias\" or row[\"SUBJECT\"] == \"eli\":\n",
    "            return \"elias\"\n",
    "        print(f\"Unknown subject: {row['SUBJECT']}\")\n",
    "        return pd.NA\n",
    "    if \"subject\" in row and pd.notna(row[\"subject\"]):\n",
    "        if row[\"subject\"] == \"airidas\" or row[\"subject\"] == \"Airidas\" or row[\"subject\"] == \"airi\":\n",
    "            return \"airidas\"\n",
    "        if row[\"subject\"] == \"elias\" or row[\"subject\"] == \"eli\":\n",
    "            return \"elias\"\n",
    "        print(f\"Unknown subject: {row['subject']}\")\n",
    "        return pd.NA\n",
    "    if row[\"sim_signature\"][:4] == \"airi\":\n",
    "        return \"airidas\"\n",
    "    if row[\"sim_signature\"][:3] == \"eli\":\n",
    "        return \"elias\"\n",
    "    return pd.NA\n",
    "\n",
    "df[\"SUBJECT\"] = df.apply(infer_subject, axis=1)\n",
    "dff = see_if_column_valid(\"SUBJECT\", df, \"Missing subjects\")\n",
    "if len(dff) == 0:\n",
    "    print(\"All subjects are valid\")\n",
    "else:\n",
    "    display(dff)\n",
    "\n",
    "df = utils.bring_to_front_important_columns(df, MOST_IMPORTANT_COLUMNS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_surv_from_info(row):\n",
    "    if row[\"survey_type\"] == \"KanoSurvey\":\n",
    "        return survey.KanoSurvey()\n",
    "    elif row[\"survey_type\"] == \"PersonalitySurvey\":\n",
    "        return survey.PersonalitySurvey()\n",
    "    else:\n",
    "        raise Exception(\"Unknown survey type: \" + row[\"survey_type\"])\n",
    "\n",
    "all_possible_asnwers = [\"I LIKE IT\", \"I EXPECT IT\", \"I AM NEUTRAL\", \"I CAN TOLERATE IT\", \"I DISLIKE IT\", \"SOMEWHAT DISAGREE\", \"DISAGREE\", \"NEUTRAL\", \"SOMEWHAT AGREE\", \"AGREE\"]\n",
    "def extract_possible_answer(value):\n",
    "    for phrase in all_possible_asnwers:\n",
    "        pattern = r'(?i)' + re.escape(phrase)\n",
    "        match = re.search(pattern, value)\n",
    "        if match:\n",
    "            # if value != phrase:\n",
    "            #     er.append([value, phrase])  \n",
    "            return match.group()\n",
    "    return value  # Return the original value if no possible answer is found\n",
    "\n",
    "############ Invalid Answers ##################\n",
    "def get_invalid_answers(value):\n",
    "    if pd.isna(value):\n",
    "        return \"\"\n",
    "    elif value == \"NaN\":\n",
    "        return \"\"\n",
    "    elif value in all_possible_asnwers:\n",
    "        return \"\"\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "def clean_simulation_QA(df) -> pd.DataFrame:\n",
    "    df['answer'] = df['answer'].apply(lambda x: x.strip())\n",
    "    for substr in utils.BLACKLIST_ANSWER_SUBSTRINGS:\n",
    "        df['answer'] = df['answer'].apply(lambda x: re.sub(substr, \"\", x))\n",
    "    df['answer'] = df['answer'].str.upper()\n",
    "    df['answer'] = df['answer'].apply(extract_possible_answer)\n",
    "\n",
    "    REMAP_MISSING_E = {\"AGRE\": \"AGREE\", \"SOMEWHAT AGRE\": \"SOMEWHAT AGREE\", \"SOMEWHAT DISAGRE\": \"SOMEWHAT DISAGREE\", \"DISAGRE\": \"DISAGREE\", \"I DON'T LIKE IT\": \"I DISLIKE IT\"}\n",
    "    df.iloc[:, 1:] = df.iloc[:, 1:].map(lambda x: REMAP_MISSING_E.get(x, x))\n",
    "\n",
    "    PARTIAL_MATCH_REMAP = {\"SOMEWHAT AG\":\"SOMEWHAT AGREE\" }\n",
    "    df[\"answer\"] = df[\"answer\"].apply(\n",
    "        lambda answer: next((value for key, value in PARTIAL_MATCH_REMAP.items() if key in answer), answer)\n",
    "    )\n",
    "\n",
    "    # Update isValid\n",
    "    df['isValid'] = df['answer'].apply(lambda x: x in all_possible_asnwers)\n",
    "\n",
    "    # if all values in isValid is true, drop the column, else print a message\n",
    "    if not df['isValid'].all():\n",
    "        print(\"Warning, some answers were not valid. See df['isValid']\")      \n",
    "\n",
    "    return df\n",
    "\n",
    "# Proces simulation output\n",
    "def add_airidas_and_elias_answers(df, surv) -> pd.DataFrame:\n",
    "    # Add airidas and elias answers\n",
    "    air = surv.test_answers[\"airidas\"]\n",
    "    eli = surv.test_answers[\"elias\"]\n",
    "\n",
    "    # Sanity Check\n",
    "    if len(air) != len(df):\n",
    "        raise Exception(f\"Survey and DF length mismatch {len(air)} != {len(df)}. Suvey type: {str(type(surv))}\")\n",
    "\n",
    "    df.insert(2, \"airidas\", air[:len(df)])\n",
    "    df.insert(3, \"elias\", eli[:len(df)])\n",
    "\n",
    "    # Convert to uppercase\n",
    "    if isinstance(surv, survey.KanoSurvey):\n",
    "        df['answer'] = df['answer'].str.upper()\n",
    "        df['airidas'] = df['airidas'].str.upper()\n",
    "        df['elias'] = df['elias'].str.upper()\n",
    "        \n",
    "    return df\n",
    "\n",
    "def remap_answers_to_integers(df, surv, remap_answer = True):\n",
    "    if isinstance(surv, survey.KanoSurvey):\n",
    "        remap_dict = {\"I EXPECT IT\": 5, \"I LIKE IT\": 4, \"I AM NEUTRAL\": 3, \"I CAN TOLERATE IT\": 2, \"I DISLIKE IT\": 1}\n",
    "        if remap_answer:\n",
    "            df['answer'] = df['answer'].str.upper()\n",
    "            df['answer'] = df['answer'].map(remap_dict)\n",
    "        df['airidas'] = df['airidas'].str.upper()\n",
    "        df['elias'] = df['elias'].str.upper()\n",
    "        \n",
    "        df['airidas'] = df['airidas'].map(remap_dict)\n",
    "        df['elias'] = df['elias'].map(remap_dict)\n",
    "    elif isinstance(surv, survey.PersonalitySurvey):\n",
    "        remap_dict = {\"AGREE\": 5, \"SOMEWHAT AGREE\": 4, \"NEUTRAL\": 3, \"SOMEWHAT DISAGREE\": 2, \"DISAGREE\": 1}\n",
    "        if remap_answer:\n",
    "            df['answer'] = df['answer'].map(remap_dict)\n",
    "\n",
    "    return df\n",
    "\n",
    "def evaluate_single_simulation_run(df, sim_row) -> dict:\n",
    "    # compute the percentage of correct answers and average loss (MAE)\n",
    "    p_corr_airidas = df['answer'].corr(df['airidas'])\n",
    "    p_corr_elias = df['answer'].corr(df['elias'])\n",
    "    mae_airi = (df['answer'] - df['airidas']).abs().sum() / len(df)\n",
    "    mae_eli = (df['answer'] - df['elias']).abs().sum() / len(df)\n",
    "\n",
    "    if sim_row[\"is_base\"]: mae, p_corr = pd.NA, pd.NA\n",
    "    elif sim_row[\"SUBJECT\"] == \"airidas\": mae, p_corr = mae_airi, p_corr_airidas\n",
    "    elif sim_row[\"SUBJECT\"] == \"elias\": mae, p_corr = mae_eli, p_corr_elias\n",
    "    else: raise Exception(\"Unknown subject\")\n",
    "\n",
    "    result_data = {\n",
    "        \"MAE\": mae,\n",
    "        \"MAE_airi\": mae_airi,\n",
    "        \"MAE_eli\": mae_eli,\n",
    "        \"p-corr\": p_corr,\n",
    "        \"p-corr_Airidas\": p_corr_airidas,\n",
    "        \"p-corr_Elias\": p_corr_elias,\n",
    "        \"question_count\": len(df),\n",
    "    }\n",
    "    return result_data\n",
    "\n",
    "\n",
    "\n",
    "ADD_TO_MOST_IMPORTANT_COLUMNS = [\"MAE_airi\", \"MAE_eli\"]\n",
    "for col in ADD_TO_MOST_IMPORTANT_COLUMNS:\n",
    "    if col not in MOST_IMPORTANT_COLUMNS:\n",
    "        MOST_IMPORTANT_COLUMNS.append(col)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Scores - Exec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVALUATE_INVALID_SIMULATIONS = True\n",
    "# If one of the questions in a simulation was answered with an invalid asnwer,\n",
    "#   should the whole sim still be used while dropping the questions with invalid answers?\n",
    "\n",
    "invalid_vals = []\n",
    "tmp = []\n",
    "\n",
    "for index, sim_row in df.iterrows():\n",
    "    sim = utils.load_sim(sim_row[\"path\"])\n",
    "    dfQA = utils.dataframe_from_QA(sim[\"QA\"])\n",
    "    with bu.MutePrint():\n",
    "        surv = get_surv_from_info(sim_row)\n",
    "        dfQA = clean_simulation_QA(dfQA)\n",
    "    dfQA = add_airidas_and_elias_answers(dfQA, surv)\n",
    "\n",
    "    ## Check for invalid values\n",
    "    if not dfQA['isValid'].all():\n",
    "        invalid_vals.extend(dfQA.loc[~dfQA['isValid'], 'answer'].tolist())\n",
    "        \n",
    "        if EVALUATE_INVALID_SIMULATIONS:\n",
    "            print(f\"{sim_row['SIMULATION_ID']} has invalid value(s). Sim will be included with dropped rows.\")\n",
    "            dfQA = dfQA[dfQA['isValid'] == True]\n",
    "        else:\n",
    "            print(f\"Skipping {sim_row['SIMULATION_ID']} due to invalid answers\")\n",
    "            continue\n",
    "\n",
    "    dfQA = remap_answers_to_integers(dfQA, surv)\n",
    "    for key, value_name in evaluate_single_simulation_run(dfQA, sim_row = sim_row).items():\n",
    "        df.at[index, key] = round(value_name, 3) if not pd.isna(value_name) else value_name\n",
    "\n",
    "# Rename values\n",
    "df['CTX_limit'] = df['CTX_limit'].astype(str)\n",
    "df.loc[df['CTX_limit'] == \"0\", 'CTX_limit'] = '1-chunk'\n",
    "\n",
    "df = utils.bring_to_front_important_columns(df, MOST_IMPORTANT_COLUMNS)\n",
    "\n",
    "if len(invalid_vals) > 0:\n",
    "    print(f\"{len(invalid_vals)} Invalid values:\")\n",
    "    display(pd.DataFrame(invalid_vals, columns=[\"Invalid Values\"]))\n",
    "    if EVALUATE_INVALID_SIMULATIONS:\n",
    "        print(\"EVALUATE_INVALID_SIMULATIONS == True. All invalid values were dropped\")\n",
    "else:\n",
    "    print(\"All values are valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vizuolisation Setup: Common \n",
    "Established some common features that may be used throughout the whole document.\n",
    "It need to be runs before the main viz, because its needed for Ditribution vizualisations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "def getGlobalColorByParam(param):\n",
    "    if param == 'SUBJECT':\n",
    "        color = 'lightblue'\n",
    "    elif param == 'survey_type':\n",
    "        color = 'lightblue'\n",
    "    elif param == 'model':\n",
    "        color = 'lightgreen'\n",
    "    else:\n",
    "        color = 'salmon'\n",
    "    return color\n",
    "\n",
    "def super_format_ax(ax, custom_x_label_size=13):\n",
    "    tick_locations = ax.get_xticks()\n",
    "    # Retrieve and wrap the existing labels\n",
    "    tick_labels = [textwrap.fill(label.get_text(), width=8, break_long_words=True, break_on_hyphens=True) \n",
    "                for label in ax.get_xticklabels()]\n",
    "    ax.set_xticks(tick_locations) \n",
    "    ax.set_xticklabels(tick_labels, fontsize=custom_x_label_size, fontweight=\"semibold\", rotation=0)\n",
    "\n",
    "    tick_locations_y = ax.get_yticks()\n",
    "    # Retrieve and wrap the existing labels\n",
    "    tick_labels_y = [textwrap.fill(label.get_text(), width=8, break_long_words=True, break_on_hyphens=True) \n",
    "                for label in ax.get_yticklabels()]\n",
    "    ax.set_yticks(tick_locations_y) \n",
    "    ax.set_yticklabels(tick_labels_y, fontsize=12,rotation=0, color='#808080')\n",
    "    ax.set_facecolor('#f5f5f5')\n",
    "\n",
    "def add_value_texts(grouped_data, ax):\n",
    "    mins, medians, maxs = grouped_data.min().values, grouped_data.median().values, grouped_data.max().values\n",
    "    pos = range(len(mins))  # Positions of the boxplots\n",
    "    vertical_offset = 0.017  # offset each text to avoid clutter\n",
    "    COLOR = '#606060'\n",
    "    for tick in pos:\n",
    "        ax.text(tick, mins[tick] - vertical_offset - 0.022, f'{mins[tick]:.2f}', horizontalalignment='center', size='10', color=COLOR) #TODO\n",
    "        ax.text(tick, medians[tick] + vertical_offset - 0.003, f'{medians[tick]:.2f}', horizontalalignment='center', size='11.5', color=COLOR) #TODO\n",
    "        ax.text(tick, maxs[tick] + vertical_offset , f'{maxs[tick]:.2f}', horizontalalignment='center', size='10', color=COLOR) #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vizualisation Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import textwrap\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "dfQAs_kano = []\n",
    "dfQAs_pers = []\n",
    "dfQAs_pers_base = []\n",
    "dfQAs_kano_base = []\n",
    "for index, sim_row in df.iterrows():\n",
    "    sim = utils.load_sim(sim_row[\"path\"])\n",
    "    dfQA = utils.dataframe_from_QA(sim[\"QA\"])\n",
    "    with bu.MutePrint():\n",
    "        surv = get_surv_from_info(sim_row)\n",
    "        dfQA = clean_simulation_QA(dfQA)\n",
    "    dfQA = add_airidas_and_elias_answers(dfQA, surv)\n",
    "    dfQA = remap_answers_to_integers(dfQA, surv)\n",
    "\n",
    "    if sim_row[\"is_base\"]:\n",
    "        if sim_row[\"survey_type\"] == \"KanoSurvey\":\n",
    "            dfQAs_kano_base.append(dfQA)\n",
    "        elif sim_row[\"survey_type\"] == \"PersonalitySurvey\":\n",
    "            dfQAs_pers_base.append(dfQA)\n",
    "    else:\n",
    "        if sim_row[\"survey_type\"] == \"KanoSurvey\":\n",
    "            dfQAs_kano.append(dfQA)\n",
    "        elif sim_row[\"survey_type\"] == \"PersonalitySurvey\":\n",
    "            dfQAs_pers.append(dfQA)\n",
    "\n",
    "\n",
    "surv_kano = survey.KanoSurvey()\n",
    "surv_pers = survey.PersonalitySurvey()\n",
    "surv_kano.df = remap_answers_to_integers(surv_kano.df, surv_kano, remap_answer=False)\n",
    "surv_pers.df = remap_answers_to_integers(surv_pers.df, surv_pers, remap_answer=False)\n",
    "\n",
    "#########################################################\n",
    "#########################################################\n",
    "\n",
    "# Assuming the dataframes and lists of dataframes are defined and imported already\n",
    "val_counts_raw = {\n",
    "    \"kano-airidas\": {\n",
    "        \"data\": surv_kano.df['airidas'].value_counts().sort_index(),\n",
    "        \"text\": \"real answers\",\n",
    "        \"color\": \"lightblue\",\n",
    "        },\n",
    "    \"pers-airidas\": {\n",
    "        \"data\": surv_pers.df['airidas'].value_counts().sort_index(),\n",
    "        \"text\": \"real answers\",\n",
    "        \"color\": \"lightblue\",\n",
    "        },\n",
    "    \"kano-elias\": {\n",
    "        \"data\": surv_kano.df['elias'].value_counts().sort_index(),\n",
    "        \"text\": \"real answers\",\n",
    "        \"color\": \"lightblue\",\n",
    "        },\n",
    "    \"pers-elias\": {\n",
    "        \"data\": surv_pers.df['elias'].value_counts().sort_index(),\n",
    "        \"text\": \"real answers\",\n",
    "        \"color\": \"lightblue\",\n",
    "        },\n",
    "    'kano-LLMs-base': {\n",
    "        \"data\": pd.concat([df['answer'] for df in dfQAs_kano_base]).value_counts().sort_index(),\n",
    "        \"text\": \"LLM base answers\",\n",
    "        \"color\": \"lightgreen\",\n",
    "        },\n",
    "    \"pers-LLMs-base\": {\n",
    "        \"data\": pd.concat([df['answer'] for df in dfQAs_pers_base]).value_counts().sort_index(),\n",
    "        \"text\": \"LLM base answers\",\n",
    "        \"color\": \"lightgreen\",\n",
    "        },\n",
    "    'kano-LLMs': {\n",
    "        \"data\": pd.concat([df['answer'] for df in dfQAs_kano]).value_counts().sort_index(),\n",
    "        \"text\": \"persona endcoded LLM answers\",\n",
    "        \"color\": \"lightgreen\",\n",
    "        },\n",
    "    \"pers-LLMs\": {\n",
    "        \"data\": pd.concat([df['answer'] for df in dfQAs_pers]).value_counts().sort_index(),\n",
    "        \"text\": \"persona endcoded LLM answers\",\n",
    "        \"color\": \"lightgreen\",\n",
    "        },\n",
    "    \n",
    "}\n",
    "\n",
    "plt.figure(figsize=(10, 12))\n",
    "for i, (key, value_name) in enumerate(val_counts_raw.items(), start=1):\n",
    "    info = value_name.copy()\n",
    "    ax = plt.subplot(4, 2, i)\n",
    "    title_text = f\"Distribution for {value_name['text']}: {key}\"\n",
    "    wrapped_title = textwrap.fill(title_text, width=30)  # You can adjust width as needed\n",
    "    plt.title(wrapped_title, fontsize=10)\n",
    "    plt.xlabel('Answer Values')\n",
    "    plt.ylabel('Percentage (%)')\n",
    "\n",
    "    value_name = value_name[\"data\"]\n",
    "    # Calculating statistics on the original unnormalized counts\n",
    "    val_array = np.repeat(value_name.index, value_name.values)\n",
    "    mean = np.mean(val_array)\n",
    "    median = np.median(val_array)\n",
    "    mode = value_name.idxmax()\n",
    "    std_dev = np.std(val_array)\n",
    "    skewness = np.sum((val_array - mean)**3) / (len(val_array) * std_dev**3)\n",
    "    mae = np.mean(np.abs(val_array - mean))\n",
    "    mae_mode = np.mean(np.abs(val_array - mode))\n",
    "\n",
    "    stats_text = (\n",
    "        f'Mean: {mean:.2f}\\n'\n",
    "        f\"Rounded Mean: {round(mean)}\\n\"\n",
    "        f'Median: {median}\\n'\n",
    "        f'Mode: {mode}\\n'\n",
    "        f'Std. Dev.: {std_dev:.2f}\\n'\n",
    "        f'Skewness: {skewness:.2f}\\n\\n'\n",
    "        f'Mean guess MAE: {mae:.3f}\\n'\n",
    "        f'(Always guess mean: \"{round(mean)}\")\\n\\n'\n",
    "        f'Mode guess MAE: {mae_mode:.3f}\\n'\n",
    "        f'(Always guess mode: {mode})\\n\\n'\n",
    "    )\n",
    "    \n",
    "    plt.annotate(stats_text, xy=(1.05, 0.5), xycoords='axes fraction',\n",
    "                    fontsize=10, ha='left', va='center')\n",
    "\n",
    "    # Normalizing data just before plotting\n",
    "    value_normalized = (value_name / value_name.sum()) * 100\n",
    "    value_normalized.plot(kind='bar', ax=ax, color=info[\"color\"], linewidth=1, edgecolor='black')\n",
    "    ax.set_ylim(0, 60)\n",
    "    super_format_ax(ax, custom_x_label_size=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surv_kano.df['elias'].value_counts().sort_index()\n",
    "value_name = val_counts_raw[\"pers-elias\"]\n",
    "value_name = value_name[\"data\"]\n",
    "val_array = np.repeat(value_name.index, value_name.values)\n",
    "mean = np.mean(val_array)\n",
    "median = np.median(val_array)\n",
    "mode = value_name.idxmax()\n",
    "std_dev = np.std(val_array)\n",
    "skewness = np.sum((val_array - mean)**3) / (len(val_array) * std_dev**3)\n",
    "mae = np.mean(np.abs(val_array - mean))\n",
    "mae_mode = np.mean(np.abs(val_array - mode))\n",
    "\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate sims\n",
    "Aggregate individual runs (simulations) into configurations (so n=3)\n",
    "\n",
    "*Since for each configuration (consistent parameter set), 3 runs (simulations) was done.\n",
    "Aggregation logic can be seen in the code below.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define how columns should be groped\n",
    "aggregation_dict = {\n",
    "    'MAE_airi': ['mean', 'std'],\n",
    "    'MAE_eli': ['mean', 'std'],\n",
    "    'MAE': ['mean', 'std'],\n",
    "    'run_number': ['count'],\n",
    "    'question_count': ['min'],\n",
    "    'p-corr_Airidas': ['mean', 'std'],\n",
    "    'p-corr_Elias': ['mean', 'std'],\n",
    "    'p-corr': ['mean', 'std'],\n",
    "}\n",
    "\n",
    "\n",
    "# Preserve the first entry of other columns\n",
    "for col in df.columns:\n",
    "    if col not in ['sim_signature', *list(aggregation_dict.keys())]:\n",
    "        aggregation_dict[col] = 'first'\n",
    "        \n",
    "# dfg stands for DataFrame Grouped.\n",
    "dfg = df.groupby('sim_signature').agg(aggregation_dict)\n",
    "\n",
    "# Renaming MultiIndex columns\n",
    "dfg.columns = ['_'.join(col).strip() if col[1] != 'first' else col[0] for col in dfg.columns.values]\n",
    "dfg.rename(columns={'run_number_count': 'n-runs'}, inplace=True)\n",
    "for key in aggregation_dict.keys():\n",
    "    if 'mean' in aggregation_dict[key]:\n",
    "        dfg.rename(columns={f\"{key}_mean\": key}, inplace=True)\n",
    "dfg = dfg.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base setup & scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate LLM bases\n",
    "And store in a dict for furhter ref."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dfg = dfg[dfg['is_base'] == True]\n",
    "global_base_scores = {\n",
    "    \"master\": base_dfg[['MAE_airi', 'MAE_eli']].mean().mean(),\n",
    "    \"mean_guess\": {\n",
    "        \"kano\": 0.9125,\n",
    "        \"pers\": 1.210\n",
    "    },\n",
    "    \"by_subject\": {\n",
    "        \"airidas\": base_dfg[['MAE_airi']].mean().mean(),\n",
    "        \"elias\": base_dfg[['MAE_eli']].mean().mean(),\n",
    "    },\n",
    "    \"by_survey\":{\n",
    "        \"KanoSurvey\": base_dfg[base_dfg['survey_type'] == \"KanoSurvey\"][['MAE_airi', 'MAE_eli']].mean().mean(),\n",
    "        \"PersonalitySurvey\": base_dfg[base_dfg['survey_type'] == \"PersonalitySurvey\"][['MAE_airi', 'MAE_eli']].mean().mean(),\n",
    "    },\n",
    "    \"by_model\":{\n",
    "        \"llama3-70b\": base_dfg[base_dfg['model'] == \"llama3-70b\"][['MAE_airi', 'MAE_eli']].mean().mean(),\n",
    "        \"llama3-8b\": base_dfg[base_dfg['model'] == \"llama3-8b\"][['MAE_airi', 'MAE_eli']].mean().mean(),\n",
    "        \"mixtral-8x22b\": base_dfg[base_dfg['model'] == \"mixtral-8x22b\"][['MAE_airi', 'MAE_eli']].mean().mean(),\n",
    "    },\n",
    "    \"by_survey_subject\":{\n",
    "        \"PersAiri\": base_dfg[base_dfg['survey_type'] == \"PersonalitySurvey\"][['MAE_airi']].mean().mean(),\n",
    "        \"PersEli\": base_dfg[base_dfg['survey_type'] == \"PersonalitySurvey\"][['MAE_eli']].mean().mean(),\n",
    "        \"KanoAiri\": base_dfg[base_dfg['survey_type'] == \"KanoSurvey\"][['MAE_airi']].mean().mean(),\n",
    "        \"KanoEli\": base_dfg[base_dfg['survey_type'] == \"KanoSurvey\"][['MAE_eli']].mean().mean(),\n",
    "    },\n",
    "    \"by_simulation\": {\n",
    "        \"kano_llama3-70b\": base_dfg[(base_dfg['sim_signature'] == 'base-kano-29_llama3-70b_V7')][['MAE_airi', 'MAE_eli']].mean().mean(),\n",
    "        \"pers_llama3-70b\": base_dfg[(base_dfg['sim_signature'] == 'base-pers-29_llama3-70b_V7')][['MAE_airi', 'MAE_eli']].mean().mean(),\n",
    "        \"kano_llama3-8b\": base_dfg[(base_dfg['sim_signature'] == 'base-kano-29_llama3-8b_V7')][['MAE_airi', 'MAE_eli']].mean().mean(),\n",
    "        \"pers_llama3-8b\": base_dfg[(base_dfg['sim_signature'] == 'base-pers-29_llama3-8b_V7')][['MAE_airi', 'MAE_eli']].mean().mean(),\n",
    "        \"kano_mixtral-8x22b\": base_dfg[(base_dfg['sim_signature'] == 'base-kano-29_mixtral-8x22b_V7')][['MAE_airi', 'MAE_eli']].mean().mean(),\n",
    "        \"pers_mixtral-8x22b\": base_dfg[(base_dfg['sim_signature'] == 'base-pers-29_mixtral-8x22b_V7')][['MAE_airi', 'MAE_eli']].mean().mean(),\n",
    "    },\n",
    "    \"atomic\": {\n",
    "        \"base-kano_llama3-70b_airi\": base_dfg[(base_dfg['sim_signature'] == 'base-kano-29_llama3-70b_V7')]['MAE_airi'].mean(),\n",
    "        \"base-kano_llama3-70b_eli\": base_dfg[(base_dfg['sim_signature'] == 'base-kano-29_llama3-70b_V7')]['MAE_eli'].mean(),\n",
    "        \"base-pers_llama3-70b_airi\": base_dfg[(base_dfg['sim_signature'] == 'base-pers-29_llama3-70b_V7')]['MAE_airi'].mean(),\n",
    "        \"base-pers_llama3-70b_eli\": base_dfg[(base_dfg['sim_signature'] == 'base-pers-29_llama3-70b_V7')]['MAE_eli'].mean(),\n",
    "        \"base-kano_llama3-8b_airi\": base_dfg[(base_dfg['sim_signature'] == 'base-kano-29_llama3-8b_V7')]['MAE_airi'].mean(),\n",
    "        \"base-kano_llama3-8b_eli\": base_dfg[(base_dfg['sim_signature'] == 'base-kano-29_llama3-8b_V7')]['MAE_eli'].mean(),\n",
    "        \"base-pers_llama3-8b_airi\": base_dfg[(base_dfg['sim_signature'] == 'base-pers-29_llama3-8b_V7')]['MAE_airi'].mean(),\n",
    "        \"base-pers_llama3-8b_eli\": base_dfg[(base_dfg['sim_signature'] == 'base-pers-29_llama3-8b_V7')]['MAE_eli'].mean(),\n",
    "        \"base-kano_mixtral-8x22b_airi\": base_dfg[(base_dfg['sim_signature'] == 'base-kano-29_mixtral-8x22b_V7')]['MAE_airi'].mean(),\n",
    "        \"base-kano_mixtral-8x22b_eli\": base_dfg[(base_dfg['sim_signature'] == 'base-kano-29_mixtral-8x22b_V7')]['MAE_eli'].mean(),\n",
    "        \"base-pers_mixtral-8x22b_airi\": base_dfg[(base_dfg['sim_signature'] == 'base-pers-29_mixtral-8x22b_V7')]['MAE_airi'].mean(),\n",
    "        \"base-pers_mixtral-8x22b_eli\": base_dfg[(base_dfg['sim_signature'] == 'base-pers-29_mixtral-8x22b_V7')]['MAE_eli'].mean(),\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dMAE Scoring\n",
    "Compare the configurations to LLM bases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_to_paired_base(row: pd.Series, df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Compares the score of a configuration (row) with the score of a paired base.\n",
    "    It use the whole dataframe as context, which should contain the base configurations.\n",
    "    The runs must be paired to bases before hand in 'base_sim_signature' column.\n",
    "\n",
    "    Returns:\n",
    "        dict: a dict with multiple values (see code)\n",
    "    \"\"\"\n",
    "    if row[\"is_base\"]:\n",
    "        return {\n",
    "            \"dMAE_airi\": pd.NA,\n",
    "            \"dMAE_eli\": pd.NA,\n",
    "            \"dMAE\": pd.NA,\n",
    "        }\n",
    "    \n",
    "    # Individual base\n",
    "    base = df[(df[\"sim_signature\"] == row[\"base_sim_signature\"])]\n",
    "    if len(base) == 0:\n",
    "        raise Exception(f\"Base not found for {row['base_sim_signature']}\")\n",
    "    if len(base) > 1:\n",
    "        raise Exception(f\"Multiple bases found for {row['base_sim_signature']}. (Make sure you are using grouped df)\")\n",
    "\n",
    "    base = base.iloc[0]\n",
    "    airi = row[\"MAE_airi\"] - base[\"MAE_airi\"]\n",
    "    eli = row[\"MAE_eli\"] - base[\"MAE_eli\"]\n",
    "    subj = airi if row[\"SUBJECT\"] == \"airidas\" else eli\n",
    "\n",
    "    return {\n",
    "        \"dMAE_airi\": airi,\n",
    "        \"dMAE_eli\": eli,\n",
    "        \"dMAE\": subj,\n",
    "        \"MAE_base\": base[\"MAE_airi\"] if row[\"SUBJECT\"] == \"airidas\" else base[\"MAE_eli\"]\n",
    "    }\n",
    "\n",
    "def compare_to_custom_base(row: pd.Series, base_val: float, base_name: str):    \n",
    "    \"\"\"\n",
    "    Compares the score of a configuration (row) with the score of a manually provided base.\n",
    "    The output keys are different from compare_to_paired_base() method, thus it can be used in addition to that.\n",
    "\n",
    "    Returns:\n",
    "        dict: a dict with multiple values (see code)\n",
    "    \"\"\"\n",
    "    if row[\"is_base\"]:\n",
    "        return {\n",
    "            f\"dMAE_{base_name}_airi\": pd.NA,\n",
    "            f\"dMAE_{base_name}_eli\": pd.NA,\n",
    "            f\"dMAE_{base_name}\": pd.NA,\n",
    "        }\n",
    "\n",
    "    airi = row[\"MAE_airi\"] - base_val\n",
    "    eli =  row[\"MAE_eli\"] - base_val\n",
    "    subj = airi if row[\"SUBJECT\"] == \"airidas\" else eli\n",
    "\n",
    "    return {\n",
    "        f\"dMAE_{base_name}_airi\": airi,\n",
    "        f\"dMAE_{base_name}_eli\": eli,\n",
    "        f\"dMAE_{base_name}\": subj,\n",
    "    }\n",
    "\n",
    "ADD_TO_MOST_IMPORTANT_COLUMNS = [\"sim_signature\",\"dMAE\", \"dMAE_airi\", \"dMAE_eli\"]\n",
    "for col in ADD_TO_MOST_IMPORTANT_COLUMNS:\n",
    "    if col in MOST_IMPORTANT_COLUMNS:\n",
    "        MOST_IMPORTANT_COLUMNS.remove(col)\n",
    "MOST_IMPORTANT_COLUMNS = ADD_TO_MOST_IMPORTANT_COLUMNS + MOST_IMPORTANT_COLUMNS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare to paired bases\n",
    "for index, sim_row in dfg.iterrows():\n",
    "    for key, value_name in compare_to_paired_base(sim_row, dfg).items():\n",
    "        dfg.at[index, key] = value_name\n",
    "\n",
    "\n",
    "## Put important columns to front.\n",
    "ADD_TO_MOST_IMPORTANT_COLUMNS = [\"sim_signature\",\"MAE\", \"MAE_base\"]\n",
    "for col in ADD_TO_MOST_IMPORTANT_COLUMNS:\n",
    "    if col in MOST_IMPORTANT_COLUMNS:\n",
    "        MOST_IMPORTANT_COLUMNS.remove(col)\n",
    "MOST_IMPORTANT_COLUMNS = ADD_TO_MOST_IMPORTANT_COLUMNS + MOST_IMPORTANT_COLUMNS\n",
    "dfg = utils.bring_to_front_important_columns(dfg, MOST_IMPORTANT_COLUMNS)\n",
    "print(f\"Total unique simulations: {len(dfg)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare to custom base\n",
    "for index, sim_row in dfg.iterrows():\n",
    "    for key, value_name in compare_to_custom_base(sim_row, base_val=global_base_scores[\"master\"], base_name=\"master\").items():\n",
    "        dfg.at[index, key] = value_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise LLM Bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import textwrap\n",
    "from matplotlib import gridspec\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "fig.suptitle('Global Bases Visualizations')\n",
    "gs = gridspec.GridSpec(4, 2)\n",
    "\n",
    "# Define axes using the GridSpec\n",
    "axs = {\n",
    "    (0, 0): fig.add_subplot(gs[0, 0]),\n",
    "    (0, 1): fig.add_subplot(gs[0, 1]),\n",
    "    (1, 0): fig.add_subplot(gs[1, 0]),\n",
    "    (1, 1): fig.add_subplot(gs[1, 1]),\n",
    "    (2, 0): fig.add_subplot(gs[2, 0]),\n",
    "    (2, 1): fig.add_subplot(gs[2, 1]),\n",
    "    (3, 0): fig.add_subplot(gs[3, 0]),\n",
    "    (3, 1): fig.add_subplot(gs[2:4, 1])  # Span 'Non-aggregated LLM' across two vertical spaces\n",
    "}\n",
    "\n",
    "# Data dictionary to align with subplot axes\n",
    "plot_data = {\n",
    "    (0, 0): ('by_survey', 'Aggregated LLM: By Survey', \"salmon\"),\n",
    "    (0, 1): ('by_subject', 'Aggregated LLM: By Subject', \"salmon\"),\n",
    "    (1, 0): ('by_survey_subject', 'Aggregated LLM: By Survey Subject', \"salmon\"),\n",
    "    (1, 1): ('by_model', 'Aggregated LLM: By Model', \"salmon\"),\n",
    "    (2, 0): ('by_simulation', 'Aggregated LLM: By Configuration', \"salmon\"),\n",
    "    (3, 0): ('mean_guess', 'Real Mean Guess bases', \"lightblue\"),\n",
    "    (3, 1): ('atomic', 'Non-aggregated (paired) LLM', \"lightgreen\")\n",
    "}\n",
    "\n",
    "# Loop through to plot each graph\n",
    "for pos, (key, title, color) in plot_data.items():\n",
    "    ax = axs[pos]\n",
    "    title_text = textwrap.fill(title, width=30)  \n",
    "    ax.set_title(title_text, fontsize=10)\n",
    "\n",
    "    if key == 'master':\n",
    "        ax.barh('Master', global_base_scores[key], color=color, edgecolor='black', linewidth=1)\n",
    "    else: \n",
    "        df = pd.DataFrame.from_dict(global_base_scores[key], orient='index', columns=['Value'])\n",
    "        bars = df.plot.barh(ax=ax, legend=False, color=color, edgecolor='black', linewidth=1)\n",
    "        \n",
    "        # Add value annotations to each bar\n",
    "        for bar in bars.patches:\n",
    "            bar_value = bar.get_width()\n",
    "            ax.text(bar.get_width() + df['Value'].max()*0.02, bar.get_y() + bar.get_height()/2, \n",
    "                    f'{bar_value:.2f}', va='center', ha='left', color='#606060', fontsize=11)\n",
    "            \n",
    "    # Style adjustments\n",
    "    ax.set_facecolor('#f5f5f5')\n",
    "    ax.set_xlim(0, 2.0)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vizualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspects the columns in text format\n",
    "\n",
    "IGNORE_COLS = [\"date\", \"EMBED_MODEL\", \"avg_tokens_in_prompt\", \"chunk_count\", \"OVERLAP_SIZE\", \"RETRIEVAL_PROMPT\", \"SIMULATION_ID\", \"path\", \"survey\", ]\n",
    "for col in dfg.columns:\n",
    "    if col in IGNORE_COLS:\n",
    "        continue  # Skip the columns from the IGNORE_COLS list\n",
    "    dtype = dfg[col].dtype\n",
    "    uniq_vals = dfg[col].unique()\n",
    "    uniq_count = len(uniq_vals)\n",
    "    na_count = dfg[col].isna().sum()\n",
    "    print(f\"{col}, dtype: {dtype}, unique count: {uniq_count}, NA values: {na_count}\", end=\"\")\n",
    "    \n",
    "    # Condition to check length of unique values and print them if < 5 and each < 25 chars\n",
    "    if uniq_count < 8 and all(len(str(val)) <= 150 for val in uniq_vals):\n",
    "        print(f\", Unique values: {uniq_vals}\", end=\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Assuming your dataframe is named `dfg`\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "filtered_df = dfg[dfg['is_base'] == False]\n",
    "parameters = ['retrieval method', 'CTX_limit', 'model', 'SUBJECT', 'survey_type']\n",
    "\n",
    "lines, labels = [], [] # To keep track of legend handles\n",
    "for i, param in enumerate(parameters, 1):\n",
    "    ax = plt.subplot(1, 5, i)\n",
    "    ax.grid(True)\n",
    "    color = getGlobalColorByParam(param)\n",
    "    sns.boxplot(x=param, y='MAE', color=color, data=filtered_df, ax=ax, linewidth=1.2)\n",
    "    #### Extract median values and their positions ######\n",
    "    grouped_data = filtered_df.groupby(param)['MAE']\n",
    "    add_value_texts(grouped_data, ax)\n",
    "    #####################################################\n",
    "    \n",
    "    plt.title(f'MAE by {param}')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.xticks(rotation=0) \n",
    "    plt.ylim(bottom=0.6, top=1.35)\n",
    "    super_format_ax(ax)\n",
    "\n",
    "    # Adding horizontal lines for guidelines\n",
    "    line1, line2 = plt.axhline(y=0.9125, color='blue', linestyle='--'), plt.axhline(y=1.210, color='red', linestyle='--')\n",
    "    if i == 1:  # Only need these once for creating the legend\n",
    "        lines.extend([line1, line2])\n",
    "        labels.extend(['Real Mean Gues for kano: 0.9125', 'Real Mean Gues for pers: 1.210'])\n",
    "\n",
    "for ax in plt.gcf().axes:  # Go over all subplots in the figure\n",
    "    ax.set_xlabel('') \n",
    "plt.tight_layout()\n",
    "plt.figlegend(lines, labels, loc='upper left', ncol=2, fontsize=12)\n",
    "plt.suptitle(f'\\n\\nMAE. (Lower is better), n={len(filtered_df)}', y=1.13, fontsize=16) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import textwrap\n",
    "\n",
    "\n",
    "# Assuming your dataframe is named `df`\n",
    "for srv in ['KanoSurvey', \"PersonalitySurvey\"]:\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    filtered_df = dfg[(dfg['is_base'] == False) & (dfg['survey_type'] == srv)]\n",
    "    parameters = ['retrieval method', 'CTX_limit', 'model', 'SUBJECT']\n",
    "    \n",
    "    lines, labels = [], [] # To keep track of legend handles\n",
    "    for i, param in enumerate(parameters, 1):\n",
    "        ax = plt.subplot(1, 4, i)\n",
    "        ax.grid(True)\n",
    "        \n",
    "        color = getGlobalColorByParam(param)\n",
    "        sns.boxplot(x=param, y='MAE', color=color, data=filtered_df, ax=ax, linewidth=2)\n",
    "        #### Extract median values and their positions ######\n",
    "        grouped_data = filtered_df.groupby(param)['MAE']\n",
    "        add_value_texts(grouped_data, ax)\n",
    "        #####################################################\n",
    "        \n",
    "        plt.title(f'MAE by {param}')\n",
    "        plt.ylabel('MAE')\n",
    "        plt.xticks(rotation=0) \n",
    "        plt.ylim(bottom=0.6, top=1.35)\n",
    "        super_format_ax(ax)\n",
    "\n",
    "        # Adding horizontal lines for guidelines\n",
    "        if srv == 'KanoSurvey':\n",
    "            lines_new = [plt.axhline(y=0.9125, color='blue', linestyle='--')]\n",
    "            labels_new = ['Real Mean Gues for kano: 0.9125']\n",
    "        elif srv == 'PersonalitySurvey':\n",
    "            lines_new = [plt.axhline(y=1.210, color='red', linestyle='--')]\n",
    "            labels_new = ['Real Mean Gues for pers: 1.210']\n",
    "        else:\n",
    "            lines_new = [plt.axhline(y=0.9125, color='blue', linestyle='--'), plt.axhline(y=1.210, color='red', linestyle='--')]\n",
    "            labels_new = ['Real Mean Guess for Kano: 0.9125', 'Real Mean Guess for pers: 1.210']\n",
    "        \n",
    "        if i == 1:  # Only need these once for creating the legend\n",
    "            lines.extend(lines_new)\n",
    "            labels.extend(labels_new)\n",
    "\n",
    "    for ax in plt.gcf().axes:  # Go over all subplots in the figure\n",
    "        ax.set_xlabel('') \n",
    "    plt.tight_layout()\n",
    "    plt.figlegend(lines, labels, loc='upper left', ncol=2, fontsize=12)\n",
    "    plt.suptitle(f'MAE for {srv}.\\n (Lower is better), n={len(filtered_df)}', y=1.07, fontsize=16) \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming your dataframe is named `df`\n",
    "for subj in ['airidas', 'elias']:\n",
    "    for srv in ['KanoSurvey', \"PersonalitySurvey\"]:\n",
    "        plt.figure(figsize=(18, 10))\n",
    "        filtered_df = dfg[(dfg['is_base'] == False) & (dfg['survey_type'] == srv) & (dfg['SUBJECT'] == subj)]\n",
    "        parameters = ['retrieval method', 'CTX_limit', 'model']\n",
    "        \n",
    "        lines, labels = [], [] # To keep track of legend handles\n",
    "        for i, param in enumerate(parameters, 1):\n",
    "            ax = plt.subplot(2, 3, i)\n",
    "            ax.grid(True)\n",
    "            \n",
    "            color = getGlobalColorByParam(param)\n",
    "            sns.boxplot(x=param, y='MAE', color=color, data=filtered_df, ax=ax, linewidth=3)\n",
    "            #### Extract median values and their positions ######\n",
    "            grouped_data = filtered_df.groupby(param)['MAE']\n",
    "            mins, medians, maxs = grouped_data.min().values, grouped_data.median().values, grouped_data.max().values\n",
    "            pos = range(len(mins))  # Positions of the boxplots\n",
    "            vertical_offset = 0.01  # offset each text to avoid clutter\n",
    "            for tick in pos:\n",
    "                ax.text(tick, mins[tick] - vertical_offset - 0.015, f'{mins[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "                ax.text(tick, medians[tick] + vertical_offset, f'{medians[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "                ax.text(tick, maxs[tick] + vertical_offset , f'{maxs[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "            #####################################################\n",
    "            \n",
    "            plt.title(f'MAE by {param}')\n",
    "            plt.ylabel('MAE')\n",
    "            plt.xticks(rotation=0) \n",
    "            plt.ylim(bottom=0.6, top=1.35) \n",
    "\n",
    "            # Adding horizontal lines for guidelines\n",
    "            if srv == 'KanoSurvey':\n",
    "                lines_new = [plt.axhline(y=0.9125, color='blue', linestyle='--')]\n",
    "                labels_new = ['Real Mean Gues for kano: 0.9125']\n",
    "            elif srv == 'PersonalitySurvey':\n",
    "                lines_new = [plt.axhline(y=1.210, color='red', linestyle='--')]\n",
    "                labels_new = ['Real Mean Gues for pers: 1.210']\n",
    "            else:\n",
    "                lines_new = [plt.axhline(y=0.9125, color='blue', linestyle='--'), plt.axhline(y=1.210, color='red', linestyle='--')]\n",
    "                labels_new = ['Real Mean Guess for Kano: 0.9125', 'Real Mean Guess for pers: 1.210']\n",
    "            \n",
    "            if i == 1:  # Only need these once for creating the legend\n",
    "                lines.extend(lines_new)\n",
    "                labels.extend(labels_new)\n",
    "        plt.tight_layout()\n",
    "        plt.figlegend(lines, labels, loc='upper left', ncol=2, fontsize=12)\n",
    "        plt.suptitle(f'MAE for {srv} & {subj}.\\n (Lower is better), n={len(filtered_df)}', y=1.05, fontsize=16)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dMAE: New"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Big boy - All 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "filtered_df = dfg[dfg['is_base'] == False]\n",
    "parameters = ['retrieval method', 'CTX_limit', 'model',  'SUBJECT', 'survey_type',]\n",
    "base_val = global_base_scores[\"master\"]\n",
    "base_name = \"master\"\n",
    "for index, sim_row in dfg.iterrows():\n",
    "    for key, value_name in compare_to_custom_base(sim_row, base_val=base_val, base_name=base_name).items():\n",
    "        dfg.at[index, key] = value_name\n",
    "\n",
    "lines, labels = [], [] # To keep track of legend handles\n",
    "for i, param in enumerate(parameters):\n",
    "    ax = plt.subplot(1, 5, i + 1)  # Horizontal layout of plots\n",
    "    ax.grid(True)\n",
    "    ax.axhline(0, color='black', linewidth=2) \n",
    "    ax.axhspan(-1, 0, color='#dcedc1', alpha=0.5)  # Stylish green background below zero\n",
    "    ax.axhspan(0, 0.5, color='#ffaaa5', alpha=0.5)   # Stylish red background above zero    # Background color above zero\n",
    "    color = getGlobalColorByParam(param)\n",
    "    #### Extract median values and their positions ######\n",
    "    grouped_data = filtered_df.groupby(param)['dMAE']\n",
    "    mins, medians, maxs = grouped_data.min().values, grouped_data.median().values, grouped_data.max().values\n",
    "    pos = range(len(mins))  # Positions of the boxplots\n",
    "    vertical_offset = 0.01  # offset each text to avoid clutter\n",
    "    \n",
    "    # for tick in pos:\n",
    "    #     ax.text(tick, mins[tick] - vertical_offset - 0.015, f'{mins[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "    #     ax.text(tick, medians[tick] + vertical_offset, f'{medians[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "    #     ax.text(tick, maxs[tick] + vertical_offset , f'{maxs[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "    #####################################################\n",
    "    sns.boxplot(x=param, y=f'dMAE', color=color, data=filtered_df)\n",
    "    plt.title(f'By {param}')\n",
    "    plt.ylabel(f'MAE_from_paired_base')\n",
    "    plt.xticks(rotation=0) \n",
    "    plt.ylim(bottom=-0.95, top=0.32)  # Adjust y-limits\n",
    "\n",
    "\n",
    "    super_format_ax(ax)\n",
    "    add_value_texts(grouped_data, ax)\n",
    "plt.tight_layout()\n",
    "plt.suptitle(f'dMAE\\n (Lower is better), n={len(filtered_df)}\\n Using paired LLM bases (y=0 for each row is set to the MAE of equivalent base)', y=1.13, fontsize=16) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Four"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = ['retrieval method', 'CTX_limit', 'SUBJECT', 'survey_type',]\n",
    "for models in [['llama3-70b'], ['llama3-8b'], ['mixtral-8x22b']]:\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    filtered_df = dfg[(dfg['is_base'] == False) & (dfg['model'].isin(models))]\n",
    "    for i, param in enumerate(parameters):\n",
    "        ax = plt.subplot(1, 4, i + 1)  # Horizontal layout of plots\n",
    "        ax.grid(True)\n",
    "        ax.axhline(0, color='black', linewidth=2) \n",
    "        ax.axhspan(-1, 0, color='green', alpha=0.16)  # Stylish green background below zero\n",
    "        ax.axhspan(0, 0.32, color='red', alpha=0.16)   # Stylish red background above zero    # Background color above zero\n",
    "        color = getGlobalColorByParam(param)\n",
    "        #### Extract median values and their positions ######\n",
    "        grouped_data = filtered_df.groupby(param)['dMAE']\n",
    "        mins, medians, maxs = grouped_data.min().values, grouped_data.median().values, grouped_data.max().values\n",
    "        pos = range(len(mins))  # Positions of the boxplots\n",
    "        vertical_offset = 0.01  # offset each text to avoid clutter\n",
    "        for tick in pos:\n",
    "            ax.text(tick, mins[tick] - vertical_offset - 0.015, f'{mins[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "            ax.text(tick, medians[tick] + vertical_offset, f'{medians[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "            ax.text(tick, maxs[tick] + vertical_offset , f'{maxs[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "        #####################################################\n",
    "        sns.boxplot(x=param, y=f'dMAE', color=color, data=filtered_df)\n",
    "        plt.title(f'By {param}')\n",
    "        plt.ylabel(f'dMAE')\n",
    "        plt.xticks(rotation=0) \n",
    "        plt.ylim(bottom=-0.3, top=0.32)  # Adjust y-limits\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(f'dMAE for {models}\\n (Lower is better), n={len(filtered_df)}\\n Using paired LLM bases (y=0 for each row is set to the MAE of equivalent base)', y=1.10, fontsize=16) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Three musketers (by subj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = ['retrieval method', 'CTX_limit', 'survey_type']\n",
    "for subj in ['airidas', 'elias']:\n",
    "    for models in [['mixtral-8x22b']]:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        filtered_df = dfg[(dfg['is_base'] == False) & (dfg['model'].isin(models)) & (dfg['SUBJECT'] == (subj))]\n",
    "        for i, param in enumerate(parameters):\n",
    "            ax = plt.subplot(1, 3, i + 1)  # Horizontal layout of plots\n",
    "            ax.grid(True)\n",
    "            ax.axhline(0, color='black', linewidth=2) \n",
    "            ax.axhspan(-1, 0, color='green', alpha=0.16)  # Stylish green background below zero\n",
    "            ax.axhspan(0, 0.32, color='red', alpha=0.16)   # Stylish red background above zero    # Background color above zero\n",
    "            color = getGlobalColorByParam(param)\n",
    "            #### Extract median values and their positions ######\n",
    "            grouped_data = filtered_df.groupby(param)['dMAE']\n",
    "            mins, medians, maxs = grouped_data.min().values, grouped_data.median().values, grouped_data.max().values\n",
    "            pos = range(len(mins))  # Positions of the boxplots\n",
    "            vertical_offset = 0.01  # offset each text to avoid clutter\n",
    "            for tick in pos:\n",
    "                ax.text(tick, mins[tick] - vertical_offset - 0.015, f'{mins[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "                ax.text(tick, medians[tick] + vertical_offset, f'{medians[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "                ax.text(tick, maxs[tick] + vertical_offset , f'{maxs[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "            #####################################################\n",
    "            sns.boxplot(x=param, y=f'dMAE', color=color, data=filtered_df)\n",
    "            plt.title(f'By {param}')\n",
    "            plt.ylabel(f'dMAE')\n",
    "            plt.xticks(rotation=0) \n",
    "            plt.ylim(bottom=-0.32, top=0.32)  # Adjust y-limits\n",
    "        plt.tight_layout()\n",
    "        plt.suptitle(f'dMAE for {models} for {subj}\\n (Lower is better), n={len(filtered_df)}\\n Using paired LLM bases (y=0 for each row is set to the MAE of equivalent base)', y=1.10, fontsize=16) \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Three musketers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = ['retrieval method', 'CTX_limit', 'SUBJECT']\n",
    "for srv in ['KanoSurvey', \"PersonalitySurvey\"]:\n",
    "    for models in [['mixtral-8x22b']]:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        filtered_df = dfg[(dfg['is_base'] == False) & (dfg['model'].isin(models)) & (dfg['survey_type'] == (srv))]\n",
    "        for i, param in enumerate(parameters):\n",
    "            ax = plt.subplot(1, 3, i + 1)  # Horizontal layout of plots\n",
    "            ax.grid(True)\n",
    "            ax.axhline(0, color='black', linewidth=2) \n",
    "            ax.axhspan(-1, 0, color='green', alpha=0.16)  # Stylish green background below zero\n",
    "            ax.axhspan(0, 0.32, color='red', alpha=0.16)   # Stylish red background above zero    # Background color above zero\n",
    "            color = getGlobalColorByParam(param)\n",
    "            #### Extract median values and their positions ######\n",
    "            grouped_data = filtered_df.groupby(param)['dMAE']\n",
    "            mins, medians, maxs = grouped_data.min().values, grouped_data.median().values, grouped_data.max().values\n",
    "            pos = range(len(mins))  # Positions of the boxplots\n",
    "            vertical_offset = 0.01  # offset each text to avoid clutter\n",
    "            for tick in pos:\n",
    "                ax.text(tick, mins[tick] - vertical_offset - 0.015, f'{mins[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "                ax.text(tick, medians[tick] + vertical_offset, f'{medians[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "                ax.text(tick, maxs[tick] + vertical_offset , f'{maxs[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "            #####################################################\n",
    "            sns.boxplot(x=param, y=f'dMAE', color=color, data=filtered_df)\n",
    "            plt.title(f'By {param}')\n",
    "            plt.ylabel(f'dMAE')\n",
    "            plt.xticks(rotation=0) \n",
    "            plt.ylim(bottom=-0.32, top=0.32)  # Adjust y-limits\n",
    "        plt.tight_layout()\n",
    "        plt.suptitle(f'dMAE for {models} for {srv}\\n (Lower is better), n={len(filtered_df)}\\n Using paired LLM bases (y=0 for each row is set to the MAE of equivalent base)', y=1.10, fontsize=16) \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two Gangsters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = ['retrieval method', 'CTX_limit']\n",
    "for subj in ['airidas', 'elias']:\n",
    "    for srv in ['KanoSurvey', \"PersonalitySurvey\"]:\n",
    "        for models in [[\"llama3-8b\",'mixtral-8x22b']]:\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            filtered_df = dfg[(dfg['is_base'] == False) & (dfg['model'].isin(models)) & (dfg['survey_type'] == (srv)) & (dfg['SUBJECT'] == (subj))]\n",
    "            base_sign = filtered_df.iloc[0][\"base_sim_signature\"]\n",
    "            base_name = utils.unclutterSignature(base_sign)\n",
    "            if subj == 'airidas': base_val = dfg[(dfg['sim_signature'] == base_sign)]['MAE_airi'].mean()\n",
    "            else: base_val = dfg[(dfg['sim_signature'] == base_sign)]['MAE_eli'].mean()\n",
    "\n",
    "            lines, labels = [], [] # To keep track of legend handles\n",
    "            for i, param in enumerate(parameters):\n",
    "                ax = plt.subplot(1, 2, i + 1)  # Horizontal layout of plots\n",
    "                ax.grid(True)\n",
    "                ax.axhline(0, color='black', linewidth=2) \n",
    "                ax.axhspan(-1, 0, color='green', alpha=0.16)  # Stylish green background below zero\n",
    "                ax.axhspan(0, 0.32, color='red', alpha=0.16)   # Stylish red background above zero    # Background color above zero\n",
    "                color = getGlobalColorByParam(param)\n",
    "                #### Extract median values and their positions ######\n",
    "                grouped_data = filtered_df.groupby(param)['dMAE']\n",
    "                mins, medians, maxs = grouped_data.min().values, grouped_data.median().values, grouped_data.max().values\n",
    "                pos = range(len(mins))  # Positions of the boxplots\n",
    "                vertical_offset = 0.01  # offset each text to avoid clutter\n",
    "                for tick in pos:\n",
    "                    ax.text(tick, mins[tick] - vertical_offset - 0.015, f'{mins[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "                    ax.text(tick, medians[tick] + vertical_offset, f'{medians[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "                    ax.text(tick, maxs[tick] + vertical_offset , f'{maxs[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "                #####################################################\n",
    "                sns.boxplot(x=param, y=f'dMAE', color=color, data=filtered_df)\n",
    "                plt.title(f'By {param}')\n",
    "                plt.ylabel(f'dMAE')\n",
    "                plt.xticks(rotation=0) \n",
    "                plt.ylim(bottom=-0.32, top=0.32)  # Adjust y-limits\n",
    "                \n",
    "                # if len(models[0]) < 2:\n",
    "                #     if srv == 'KanoSurvey':\n",
    "                #         lines_new = [plt.axhline(y=0.9125 - base_val, color='blue', linestyle='--', linewidth=2.5), plt.axhline(y=1.210 - base_val, color='red', linestyle='--')]\n",
    "                #         labels_new = [f'Real Mean Guess base for kano: {round(0.9125 - base_val,3)}', f'Real Mean Guess base for pers: {round(1.210 - base_val,3)}']\n",
    "\n",
    "                #     elif srv == 'PersonalitySurvey':\n",
    "                #         lines_new = [plt.axhline(y=1.210 - base_val, color='red', linestyle='--', linewidth=2.5), plt.axhline(y=0.9125 - base_val, color='blue', linestyle='--')]\n",
    "                #         labels_new = [f'Real Mean Guess base for pers: {round(1.210 - base_val,3)}',f'Real Mean Guess base for Kano: {round(0.9125 - base_val,3)}']\n",
    "                #     else:\n",
    "                #         lines_new = [plt.axhline(y=0.9125 - base_val, color='blue', linestyle='--'), plt.axhline(y=1.210 - base_val, color='red', linestyle='--')]\n",
    "                #         labels_new = [f'Real Mean Guess base for Kano: {round(0.9125 - base_val,3)}', f'Real Mean Guess base for pers: {round(1.210 - base_val,3)}']\n",
    "\n",
    "                # if i == 1:  # Only need these once for creating the legend\n",
    "                #     lines.extend(lines_new)\n",
    "                #     labels.extend(labels_new)\n",
    "\n",
    "            # plt.figlegend(lines, labels, loc='upper left', ncol=2, fontsize=10)\n",
    "            plt.tight_layout()\n",
    "            plt.suptitle(f'\\n\\ndMAE for {models} for {srv} for {subj}\\n (Lower is better), n={len(filtered_df)}\\n  Using paired LLM bases (y=0 for each row is set to the MAE of equivalent base)', y=1.15, fontsize=11) \n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dMAE: Old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Big boy - All 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 6))\n",
    "filtered_df = dfg[dfg['is_base'] == False]\n",
    "parameters = ['retrieval method', 'CTX_limit', 'model',  'SUBJECT', 'survey_type',]\n",
    "base_val = global_base_scores[\"master\"]\n",
    "base_name = \"master\"\n",
    "for index, sim_row in dfg.iterrows():\n",
    "    for key, value_name in compare_to_custom_base(sim_row, base_val=base_val, base_name=base_name).items():\n",
    "        dfg.at[index, key] = value_name\n",
    "\n",
    "lines, labels = [], [] # To keep track of legend handles\n",
    "for i, param in enumerate(parameters):\n",
    "    ax = plt.subplot(1, 5, i + 1)  # Horizontal layout of plots\n",
    "    ax.grid(True)\n",
    "    ax.axhline(0, color='black', linewidth=2) \n",
    "    ax.axhspan(-0.55, 0, color='green', alpha=0.16)  # Stylish green background below zero\n",
    "    ax.axhspan(0, 0.32, color='red', alpha=0.16)   # Stylish red background above zero    # Background color above zero\n",
    "    color = getGlobalColorByParam(param)\n",
    "    #### Extract median values and their positions ######\n",
    "    grouped_data = filtered_df.groupby(param)['dMAE_master']\n",
    "    mins, medians, maxs = grouped_data.min().values, grouped_data.median().values, grouped_data.max().values\n",
    "    pos = range(len(mins))  # Positions of the boxplots\n",
    "    vertical_offset = 0.01  # offset each text to avoid clutter\n",
    "    for tick in pos:\n",
    "        ax.text(tick, mins[tick] - vertical_offset - 0.015, f'{mins[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "        ax.text(tick, medians[tick] + vertical_offset, f'{medians[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "        ax.text(tick, maxs[tick] + vertical_offset , f'{maxs[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "    #####################################################\n",
    "    sns.boxplot(x=param, y=f'dMAE_{base_name}', color=color, data=filtered_df)\n",
    "    plt.title(f'By {param}')\n",
    "    plt.ylabel(f'dMAE_{base_name}  {round(base_val,3)}')\n",
    "    plt.xticks(rotation=0) \n",
    "    plt.ylim(bottom=-0.55, top=0.32)  # Adjust y-limits\n",
    "\n",
    "    lines_new = [plt.axhline(y=0.9125 - base_val, color='blue', linestyle='--'), plt.axhline(y=1.210 - base_val, color='red', linestyle='--')]\n",
    "    labels_new = [f'Real Mean Guess base for Kano: {round(0.9125 - base_val,3)}', f'Real Mean Guess base for pers: {round(1.210 - base_val,3)}']\n",
    "\n",
    "    if i == 1:  # Only need these once for creating the legend\n",
    "        lines.extend(lines_new)\n",
    "        labels.extend(labels_new)\n",
    "\n",
    "plt.figlegend(lines, labels, loc='upper left', ncol=2, fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.suptitle(f'dMAE\\n (Lower is better), n={len(filtered_df)}\\n Aggregated LLM base: {base_name} = {round(base_val,3)} (y=0 is at MAE {round(base_val,3)})', y=1.10, fontsize=16) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Four"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for srv in ['KanoSurvey', \"PersonalitySurvey\"]:\n",
    "    base_val = global_base_scores[\"by_survey\"][srv]\n",
    "    base_name = srv[:4].lower()\n",
    "    for index, sim_row in dfg.iterrows():\n",
    "        for key, value_name in compare_to_custom_base(sim_row, base_val=base_val, base_name=base_name).items():\n",
    "            dfg.at[index, key] = value_name\n",
    "\n",
    "    filtered_df = dfg[(dfg['is_base'] == False) & (dfg['survey_type'] == srv)]\n",
    "    parameters = ['retrieval method', 'CTX_limit',  'model','SUBJECT',]\n",
    "    plt.figure(figsize=(18, 6))  # Adjust the figure size for horizontal layouts\n",
    "    lines, labels = [], [] # To keep track of legend handles\n",
    "    for i, param in enumerate(parameters):\n",
    "        ax = plt.subplot(1, 4, i + 1)  # Horizontal layout of plots\n",
    "        ax.grid(True)\n",
    "        ax.axhline(0, color='black', linewidth=2) \n",
    "        ax.axhspan(-0.55, 0, color='green', alpha=0.16)  # Stylish green background below zero\n",
    "        ax.axhspan(0, 0.32, color='red', alpha=0.16)   # Stylish red background above zero    # Background color above zero\n",
    "        color = getGlobalColorByParam(param)\n",
    "        #### Extract median values and their positions ######\n",
    "        grouped_data = filtered_df.groupby(param)[f'dMAE_{base_name}']\n",
    "        mins, medians, maxs = grouped_data.min().values, grouped_data.median().values, grouped_data.max().values\n",
    "        pos = range(len(mins))  # Positions of the boxplots\n",
    "        vertical_offset = 0.01  # offset each text to avoid clutter\n",
    "        for tick in pos:\n",
    "            ax.text(tick, mins[tick] - vertical_offset - 0.015, f'{mins[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "            ax.text(tick, medians[tick] + vertical_offset, f'{medians[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "            ax.text(tick, maxs[tick] + vertical_offset , f'{maxs[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "        #####################################################\n",
    "        sns.boxplot(x=param, y=f'dMAE_{base_name}', color=color, data=filtered_df)\n",
    "        plt.title(f'By {param}')\n",
    "        plt.ylabel(f'dMAE_{base_name}  {round(base_val,3)}')\n",
    "        plt.xticks(rotation=0) \n",
    "        plt.ylim(bottom=-0.55, top=0.32)  # Adjust y-limits\n",
    "        \n",
    "        if srv == 'KanoSurvey':\n",
    "            lines_new = [plt.axhline(y=0.9125 - base_val, color='blue', linestyle='--', linewidth=2.5), plt.axhline(y=1.210 - base_val, color='red', linestyle='--')]\n",
    "            labels_new = [f'Real Mean Guess base for kano: {round(0.9125 - base_val,3)}', f'Real Mean Guess base for pers: {round(1.210 - base_val,3)}']\n",
    "\n",
    "        elif srv == 'PersonalitySurvey':\n",
    "            lines_new = [plt.axhline(y=1.210 - base_val, color='red', linestyle='--', linewidth=2.5), plt.axhline(y=0.9125 - base_val, color='blue', linestyle='--')]\n",
    "            labels_new = [f'Real Mean Guess base for pers: {round(1.210 - base_val,3)}',f'Real Mean Guess base for Kano: {round(0.9125 - base_val,3)}']\n",
    "        else:\n",
    "            lines_new = [plt.axhline(y=0.9125 - base_val, color='blue', linestyle='--'), plt.axhline(y=1.210 - base_val, color='red', linestyle='--')]\n",
    "            labels_new = [f'Real Mean Guess base for Kano: {round(0.9125 - base_val,3)}', f'Real Mean Guess base for pers: {round(1.210 - base_val,3)}']\n",
    "\n",
    "        if i == 1:  # Only need these once for creating the legend\n",
    "            lines.extend(lines_new)\n",
    "            labels.extend(labels_new)\n",
    "    \n",
    "    plt.figlegend(lines, labels, loc='upper left', ncol=2, fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(f'dMAE for {srv}\\n (Lower is better), n={len(filtered_df)}\\n Aggregated LLM base: {base_name} = {round(base_val,3)} (y=0 is at MAE {round(base_val,3)})', y=1.10, fontsize=16) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Three Musketers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subj in ['airidas', 'elias']:\n",
    "    for srv in ['KanoSurvey', \"PersonalitySurvey\"]:\n",
    "        base_name = srv[:4]\n",
    "        if subj == 'airidas': base_name += 'Airi'\n",
    "        else: base_name += 'Eli'\n",
    "        base_val = global_base_scores[\"by_survey_subject\"][base_name]\n",
    "        for index, sim_row in dfg.iterrows():\n",
    "            for key, value_name in compare_to_custom_base(sim_row, base_val=base_val, base_name=base_name).items():\n",
    "                dfg.at[index, key] = value_name\n",
    "\n",
    "        filtered_df = dfg[(dfg['is_base'] == False) & (dfg['survey_type'] == srv) & (dfg['SUBJECT'] == subj)]\n",
    "        parameters = ['retrieval method', 'CTX_limit', 'model']\n",
    "        plt.figure(figsize=(18, 6))  # Adjust the figure size for horizontal layouts\n",
    "        lines, labels = [], [] # To keep track of legend handles\n",
    "        for i, param in enumerate(parameters):\n",
    "            ax = plt.subplot(1, 3, i + 1)  # Horizontal layout of plots\n",
    "            ax.grid(True)\n",
    "            ax.axhline(0, color='black', linewidth=2) \n",
    "            ax.axhspan(-0.55, 0, color='green', alpha=0.16)  # Stylish green background below zero\n",
    "            ax.axhspan(0, 0.32, color='red', alpha=0.16)   # Stylish red background above zero    # Background color above zero\n",
    "            color = getGlobalColorByParam(param)\n",
    "            #### Extract median values and their positions ######\n",
    "            grouped_data = filtered_df.groupby(param)[f'dMAE_{base_name}']\n",
    "            mins, medians, maxs = grouped_data.min().values, grouped_data.median().values, grouped_data.max().values\n",
    "            pos = range(len(mins))  # Positions of the boxplots\n",
    "            vertical_offset = 0.01  # offset each text to avoid clutter\n",
    "            for tick in pos:\n",
    "                ax.text(tick, mins[tick] - vertical_offset - 0.015, f'{mins[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "                ax.text(tick, medians[tick] + vertical_offset, f'{medians[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "                ax.text(tick, maxs[tick] + vertical_offset , f'{maxs[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "            #####################################################\n",
    "            sns.boxplot(x=param, y=f'dMAE_{base_name}', color=color, data=filtered_df)\n",
    "            plt.title(f'By {param}')\n",
    "            plt.ylabel(f'dMAE_{base_name}  {round(base_val,3)}')\n",
    "            plt.xticks(rotation=0) \n",
    "            plt.ylim(bottom=-0.55, top=0.32)  # Adjust y-limits\n",
    "            \n",
    "            if srv == 'KanoSurvey':\n",
    "                lines_new = [plt.axhline(y=0.9125 - base_val, color='blue', linestyle='--', linewidth=2.5), plt.axhline(y=1.210 - base_val, color='red', linestyle='--')]\n",
    "                labels_new = [f'Real Mean Guess base for kano: {round(0.9125 - base_val,3)}', f'Real Mean Guess base for pers: {round(1.210 - base_val,3)}']\n",
    "\n",
    "            elif srv == 'PersonalitySurvey':\n",
    "                lines_new = [plt.axhline(y=1.210 - base_val, color='red', linestyle='--', linewidth=2.5), plt.axhline(y=0.9125 - base_val, color='blue', linestyle='--')]\n",
    "                labels_new = [f'Real Mean Guess base for pers: {round(1.210 - base_val,3)}',f'Real Mean Guess base for Kano: {round(0.9125 - base_val,3)}']\n",
    "            else:\n",
    "                lines_new = [plt.axhline(y=0.9125 - base_val, color='blue', linestyle='--'), plt.axhline(y=1.210 - base_val, color='red', linestyle='--')]\n",
    "                labels_new = [f'Real Mean Guess base for Kano: {round(0.9125 - base_val,3)}', f'Real Mean Guess base for pers: {round(1.210 - base_val,3)}']\n",
    "\n",
    "            if i == 1:  # Only need these once for creating the legend\n",
    "                lines.extend(lines_new)\n",
    "                labels.extend(labels_new)\n",
    "        \n",
    "        plt.figlegend(lines, labels, loc='upper left', ncol=2, fontsize=10)\n",
    "        plt.tight_layout()\n",
    "        plt.suptitle(f'dMAE for {srv} for {subj}\\n (Lower is better), n={len(filtered_df)}\\n Aggregated LLM base: {base_name} = {round(base_val,3)} (y=0 is at MAE {round(base_val,3)})', y=1.10, fontsize=16) \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two Gansters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for llm in ['llama3-8b', 'llama3-70b', 'mixtral-8x22b']:\n",
    "    for subj in ['airidas', 'elias']:\n",
    "        for srv in ['KanoSurvey', \"PersonalitySurvey\"]:\n",
    "            filtered_df = dfg[(dfg['is_base'] == False) & (dfg['survey_type'] == srv) & (dfg['SUBJECT'] == subj) & (dfg['model'] == llm)]\n",
    "            base_sign = filtered_df.iloc[0][\"base_sim_signature\"]\n",
    "            base_name = utils.unclutterSignature(base_sign)\n",
    "            if subj == 'airidas': base_val = dfg[(dfg['sim_signature'] == base_sign)]['MAE_airi'].mean()\n",
    "            else: base_val = dfg[(dfg['sim_signature'] == base_sign)]['MAE_eli'].mean()\n",
    "            parameters = ['retrieval method', 'CTX_limit']\n",
    "            plt.figure(figsize=(10, 6))  # Adjust the figure size for horizontal layouts\n",
    "            lines, labels = [], [] # To keep track of legend handles\n",
    "            for i, param in enumerate(parameters):\n",
    "                ax = plt.subplot(1, 2, i + 1)  # Horizontal layout of plots\n",
    "                ax.grid(True)\n",
    "                ax.axhline(0, color='black', linewidth=2) \n",
    "                ax.axhspan(-0.95, 0, color='green', alpha=0.16)  # Stylish green background below zero\n",
    "                ax.axhspan(0, 0.32, color='red', alpha=0.16)   # Stylish red background above zero    # Background color above zero\n",
    "                color = getGlobalColorByParam(param)\n",
    "                #### Extract median values and their positions ######\n",
    "                grouped_data = filtered_df.groupby(param)[f'dMAE']\n",
    "                mins, medians, maxs = grouped_data.min().values, grouped_data.median().values, grouped_data.max().values\n",
    "                pos = range(len(mins))  # Positions of the boxplots\n",
    "                vertical_offset = 0.01  # offset each text to avoid clutter\n",
    "                for tick in pos:\n",
    "                    ax.text(tick, mins[tick] - vertical_offset - 0.015, f'{mins[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "                    ax.text(tick, medians[tick] + vertical_offset, f'{medians[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "                    ax.text(tick, maxs[tick] + vertical_offset , f'{maxs[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "                #####################################################\n",
    "                sns.boxplot(x=param, y=f'dMAE', color=color, data=filtered_df)\n",
    "                plt.title(f'By {param}')\n",
    "                plt.ylabel(f'dMAE_atomic  {round(base_val,3)}')\n",
    "                plt.xticks(rotation=0) \n",
    "                if base_val > 1.6: plt.ylim(bottom=-0.95, top=0.1) \n",
    "                else: plt.ylim(bottom=-0.55, top=0.32)  # Adjust y-limits\n",
    "                \n",
    "                if srv == 'KanoSurvey':\n",
    "                    lines_new = [plt.axhline(y=0.9125 - base_val, color='blue', linestyle='--', linewidth=2.5), plt.axhline(y=1.210 - base_val, color='red', linestyle='--')]\n",
    "                    labels_new = [f'Real Mean Guess base for kano: {round(0.9125 - base_val,3)}', f'Real Mean Guess base for pers: {round(1.210 - base_val,3)}']\n",
    "                elif srv == 'PersonalitySurvey':\n",
    "                    lines_new = [plt.axhline(y=1.210 - base_val, color='red', linestyle='--', linewidth=2.5), plt.axhline(y=0.9125 - base_val, color='blue', linestyle='--')]\n",
    "                    labels_new = [f'Real Mean Guess base for pers: {round(1.210 - base_val,3)}',f'Real Mean Guess base for Kano: {round(0.9125 - base_val,3)}']\n",
    "                else:\n",
    "                    lines_new = [plt.axhline(y=0.9125 - base_val, color='blue', linestyle='--'), plt.axhline(y=1.210 - base_val, color='red', linestyle='--')]\n",
    "                    labels_new = [f'Real Mean Guess base for Kano: {round(0.9125 - base_val,3)}', f'Real Mean Guess base for pers: {round(1.210 - base_val,3)}']\n",
    "\n",
    "                if i == 1:  # Only need these once for creating the legend\n",
    "                    lines.extend(lines_new)\n",
    "                    labels.extend(labels_new)\n",
    "            \n",
    "            plt.figlegend(lines, labels, loc='upper left', ncol=2, fontsize=10)\n",
    "            plt.tight_layout()\n",
    "            plt.suptitle(f'\\n\\ndMAE for {srv} for {subj} for {llm}\\n (Lower is better), n={len(filtered_df)}\\n Atomic LLM base: {base_name} = {round(base_val,3)} (y=0 is at MAE {round(base_val,3)})', y=1.16, fontsize=13) \n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = dfg[(dfg['is_base'] == False) & (dfg['survey_type'] == \"KanoSurvey\") & (dfg['SUBJECT'] == \"airidas\") & (dfg['model'] == \"llama3-8b\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dfg[(base_dfg['sim_signature'] == 'base-pers-29_mixtral-8x22b_V7')]['MAE_eli'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ultimate Universal (UU) graph\n",
    "Combines MAE&dMAE\n",
    "\n",
    "(We invented the name for it ourselves)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def various_or_single(x):\n",
    "    \"\"\"\n",
    "    Determines, whether a clumnn has uniform (all the same) values or they vary. \n",
    "    Returns:\n",
    "        str: Either the uniform single value, or literal '(various)'\n",
    "    \"\"\"\n",
    "    if x.nunique() == 1:\n",
    "        return x.iloc[0]\n",
    "    else:\n",
    "        return '(various)'\n",
    "    \n",
    "def format_ctx_limit(row: pd.Series) -> str:\n",
    "    \"\"\"\n",
    "    Formats the CTX_limit column for better readability.\n",
    "\n",
    "    Args:\n",
    "        row (pd.Series): A row of the dataframe\n",
    "    \n",
    "    Returns:\n",
    "        str: A formatted string\n",
    "    \"\"\"\n",
    "    formatted = \"max \"\n",
    "    if row[\"CTX_limit\"] == \"1-chunk\":\n",
    "        formatted += f\"{row['prompt_tokens_max']}\"\n",
    "    else:\n",
    "        formatted += row[\"CTX_limit\"]\n",
    "\n",
    "    return formatted + \" tk.\"\n",
    "\n",
    "def format_subject(subject: str) -> str:\n",
    "    if subject == 'airidas':\n",
    "        return 'Airidas'\n",
    "    if subject == 'elias':\n",
    "        return 'Elias'\n",
    "    else:\n",
    "        return subject\n",
    "    \n",
    "\n",
    "def anonymize_subject(subject: str) -> str:\n",
    "    if subject == 'airidas':\n",
    "        return 'Subj-L'\n",
    "    if subject == 'elias':\n",
    "        return 'Subj-S'\n",
    "    else:\n",
    "        return subject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UU Aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Determine aggregation methods based on column data types\n",
    "aggregations = {}\n",
    "for column, dtype in dfg.dtypes.items():\n",
    "    if dtype in ['int64', 'float64']:  # Add other numeric types if needed\n",
    "        aggregations[column] = 'mean'\n",
    "    else:\n",
    "        aggregations[column] = various_or_single\n",
    "\n",
    "# Apply group by with the dynamic aggregation dictionary\n",
    "group_cols = ['SUBJECT', 'model', \"survey_type\"]\n",
    "df_grouped = dfg.groupby(group_cols).agg(aggregations).drop(columns=group_cols).reset_index()\n",
    "graphs = [\n",
    "    {\n",
    "        \"srv\": \"PersonalitySurvey\",\n",
    "    },\n",
    "    {\n",
    "        \"srv\": \"KanoSurvey\",\n",
    "    },\n",
    "]\n",
    "\n",
    "for graph in graphs:\n",
    "    # Calculate start and end points\n",
    "    ddf = df_grouped[(df_grouped['is_base'] == False) & (df_grouped['survey_type'] == graph[\"srv\"])].sort_values(ascending=False, by='MAE').reset_index()\n",
    "    ddf = ddf.drop(columns=[\"index\"])\n",
    "\n",
    "    ddf['start'] = ddf['MAE_base']\n",
    "    ddf['end'] = ddf['MAE_base'] + ddf['dMAE']\n",
    "\n",
    "    # Create figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(23, 3))\n",
    "    fig.patch.set_facecolor('#efdbbd')\n",
    "    # Plot each bar\n",
    "    for i, row in ddf.iterrows():\n",
    "    \n",
    "        color = 'lightgreen' if row['dMAE'] <= 0 else 'salmon'\n",
    "        group_signature = \" \".join([str(row[col]) for col in group_cols])\n",
    "        ax.barh(group_signature, row['end'] - row['start'], left=row['start'], color=color)\n",
    "        ax.plot([row['MAE_base'], row['MAE_base']], [i-0.4, i+0.4], color='black', linewidth=2)\n",
    "        \n",
    "\n",
    "    ax.set_yticks([]) # Remove Y-axis tick labels since we will replace them with detailed text\n",
    "    ax.set_xlim(0.60, 1.82)\n",
    "    table_text_props = {'verticalalignment': 'center', 'horizontalalignment': 'right'}\n",
    "\n",
    "    gap = -0.18\n",
    "    start = 0.58\n",
    "    x_positions = []\n",
    "    for i in range(4):\n",
    "        x_positions.append(start + gap * i)\n",
    "\n",
    "    for i in range(len(ddf)):\n",
    "        ax.text(x=x_positions[0], y=i, s=ddf.loc[i, 'SUBJECT'], **table_text_props)\n",
    "        ax.text(x=x_positions[1], y=i, s=ddf.loc[i, 'model'], **table_text_props)\n",
    "        # The below is commented. Uncomment if you want to indicate that the two vars are (variable). Also uncomment two other lines (search COMMENT#4000)\n",
    "        # ax.text(x=x_positions[2], y=i, s=ddf.loc[i, 'retrieval method'], **table_text_props)\n",
    "        # ax.text(x=x_positions[3], y=i, s=ddf.loc[i, 'CTX_limit'], **table_text_props)\n",
    "        ax.axhline(y=i - 0.5, xmin=0, xmax=1, color='lightgray', linewidth=0.8)\n",
    "        \n",
    "\n",
    "    # Add table column headers\n",
    "    ax.text(x=x_positions[0], y=len(ddf), s=\"SUBJECT\", fontweight='bold', **table_text_props)\n",
    "    ax.text(x=x_positions[1], y=len(ddf), s=\"model\", fontweight='bold', **table_text_props)\n",
    "     # The below is commented. Uncomment if you want to indicate that the two vars are (variable). Also uncomment two other lines (search COMMENT#4000)\n",
    "    # ax.text(x=x_positions[2], y=len(ddf), s='retrieval', fontweight='bold', **table_text_props)\n",
    "    # ax.text(x=x_positions[3], y=len(ddf), s='CTX_limit', fontweight='bold', **table_text_props)\n",
    "    \n",
    "    # Adjust the plot layout to make room for the table but with smaller gaps\n",
    "    plt.subplots_adjust(right=0.55)\n",
    "\n",
    "    lines = []\n",
    "    labels = []\n",
    "        # Adding horizontal lines for guidelines\n",
    "    if graph[\"srv\"] == 'KanoSurvey':\n",
    "        lines_new = [plt.axvline(x=0.9125, color='blue', linestyle='--')]\n",
    "        labels_new = ['Real Mean Guess for kano: 0.9125']\n",
    "    elif graph[\"srv\"] == 'PersonalitySurvey':\n",
    "        lines_new = [plt.axvline(x=1.210, color='red', linestyle='--')]\n",
    "        labels_new = ['Real Mean Guess for pers: 1.210']\n",
    "    else:\n",
    "        lines_new = [plt.axvline(x=0.9125, color='blue', linestyle='--'), plt.axhline(y=1.210, color='red', linestyle='--')]\n",
    "        labels_new = ['Real Mean Guess for Kano: 0.9125', 'Real Mean Guess for pers: 1.210']\n",
    "    \n",
    "    lines.extend(lines_new)\n",
    "    labels.extend(labels_new)\n",
    "    plt.figlegend(lines, labels, loc='upper left', ncol=2, fontsize=10)\n",
    "\n",
    "\n",
    "    # Adding labels and title\n",
    "    ax.set_xlabel('MAE')\n",
    "    ax.set_title('Change in MAE from Base')\n",
    "    super_format_ax(ax)\n",
    "    ax.set_facecolor('#f8eee0')\n",
    "\n",
    "    fig.suptitle(f\"Survey type: {graph['srv']}\", fontsize=14, x=0.26, y=1.05)\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UU Granular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = [\n",
    "    {\n",
    "        \"srv\": \"PersonalitySurvey\",\n",
    "    },\n",
    "    {\n",
    "        \"srv\": \"KanoSurvey\",\n",
    "    },\n",
    "]\n",
    "\n",
    "for graph in graphs:\n",
    "    # Calculate start and end points\n",
    "    ddf = dfg[(dfg['is_base'] == False) & (dfg['survey_type'] == graph[\"srv\"])].sort_values(ascending=False, by='MAE').reset_index()\n",
    "\n",
    "    ddf['start'] = ddf['MAE_base']\n",
    "    ddf['end'] = ddf['MAE_base'] + ddf['dMAE']\n",
    "\n",
    "    # Create figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(23, 8))\n",
    "    fig.patch.set_facecolor('#efdbbd')\n",
    "\n",
    "    # Plot each bar\n",
    "    for i, row in ddf.iterrows():\n",
    "        color = 'lightgreen' if row['dMAE'] <= 0 else 'salmon' \n",
    "        ax.barh(row['sim_signature'], row['end'] - row['start'], left=row['start'], color=color)\n",
    "        ax.plot([row['MAE_base'], row['MAE_base']], [i-0.4, i+0.4], color='black', linewidth=2)\n",
    "\n",
    "    ax.set_yticks([]) # Remove Y-axis tick labels since we will replace them with detailed text\n",
    "    ax.set_xlim(0.60, 1.82)\n",
    "    table_text_props = {'verticalalignment': 'center', 'horizontalalignment': 'right'}\n",
    "\n",
    "    gap = -0.18\n",
    "    start = 0.58\n",
    "    x_positions = []\n",
    "    for i in range(4):\n",
    "        x_positions.append(start + gap * i)\n",
    "    print(x_positions)\n",
    "\n",
    "    for i in range(len(ddf)):\n",
    "        ax.text(x=x_positions[0], y=i, s=ddf.loc[i, 'SUBJECT'], **table_text_props)\n",
    "        ax.text(x=x_positions[1], y=i, s=ddf.loc[i, 'CTX_limit'], **table_text_props)\n",
    "        ax.text(x=x_positions[2], y=i, s=ddf.loc[i, 'model'], **table_text_props)\n",
    "        ax.text(x=x_positions[3], y=i, s=ddf.loc[i, 'retrieval method'], **table_text_props)\n",
    "        # Draw horizontal lines between rows\n",
    "        ax.axhline(y=i - 0.5, xmin=0, xmax=1, color='lightgray', linewidth=0.8)\n",
    "\n",
    "    # Add table column headers\n",
    "    ax.text(x=x_positions[0], y=len(ddf), s=\"SUBJECT\", fontweight='bold', **table_text_props)\n",
    "    ax.text(x=x_positions[1], y=len(ddf), s=\"CTX_limit\", fontweight='bold', **table_text_props)\n",
    "    ax.text(x=x_positions[2], y=len(ddf), s=\"model\", fontweight='bold', **table_text_props)\n",
    "    ax.text(x=x_positions[3], y=len(ddf), s=\"retrieval\", fontweight='bold', **table_text_props)\n",
    "    # Adjust the plot layout to make room for the table but with smaller gaps\n",
    "    plt.subplots_adjust(right=0.55)\n",
    "\n",
    "    lines = []\n",
    "    labels = []\n",
    "        # Adding horizontal lines for guidelines\n",
    "    if graph[\"srv\"] == 'KanoSurvey':\n",
    "        lines_new = [plt.axvline(x=0.9125, color='blue', linestyle='--')]\n",
    "        labels_new = ['Real Mean Guess for kano: 0.9125']\n",
    "    elif graph[\"srv\"] == 'PersonalitySurvey':\n",
    "        lines_new = [plt.axvline(x=1.210, color='red', linestyle='--')]\n",
    "        labels_new = ['Real Mean Guess for pers: 1.210']\n",
    "    else:\n",
    "        lines_new = [plt.axvline(x=0.9125, color='blue', linestyle='--'), plt.axhline(y=1.210, color='red', linestyle='--')]\n",
    "        labels_new = ['Real Mean Guess for Kano: 0.9125', 'Real Mean Guess for pers: 1.210']\n",
    "    \n",
    "    lines.extend(lines_new)\n",
    "    labels.extend(labels_new)\n",
    "    plt.figlegend(lines, labels, loc='upper left', ncol=2, fontsize=10)\n",
    "\n",
    "    # Adding labels and title\n",
    "    ax.set_xlabel('MAE')\n",
    "    ax.set_title('Change in MAE from Base')\n",
    "    super_format_ax(ax)\n",
    "    ax.set_facecolor('#f8eee0')\n",
    "\n",
    "    fig.suptitle(f\"Survey type: {graph['srv']}\", fontsize=16, x=0.22, y=0.95)\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UU v2 Group Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply group by with the dynamic aggregation dictionary\n",
    "group_cols = ['SUBJECT', 'model', \"survey_type\"]\n",
    "dfg_nobase = dfg[dfg['is_base'] == False]\n",
    "\n",
    "# Get the rows with best performance (min MAE) for each group\n",
    "ddbf = dfg_nobase.loc[dfg_nobase.groupby(['SUBJECT', 'model', 'survey_type'])['MAE'].idxmin()]\n",
    "graphs = [\n",
    "    {\n",
    "        \"srv\": \"PersonalitySurvey\",\n",
    "    },\n",
    "    {\n",
    "        \"srv\": \"KanoSurvey\",\n",
    "    },\n",
    "]\n",
    "\n",
    "for graph in graphs:\n",
    "    # Calculate start and end points\n",
    "    ddf = ddbf[(ddbf['survey_type'] == graph[\"srv\"])].sort_values(ascending=False, by='MAE').reset_index()\n",
    "    ddf = ddf.drop(columns=[\"index\"])\n",
    "\n",
    "    ddf['start'] = ddf['MAE_base']\n",
    "    ddf['end'] = ddf['MAE_base'] + ddf['dMAE']\n",
    "\n",
    "    # Create figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(23, 3))\n",
    "    fig.patch.set_facecolor('#efdbbd')\n",
    "    # Plot each bar\n",
    "    for i, row in ddf.iterrows():\n",
    "    \n",
    "        color = 'lightgreen' if row['dMAE'] <= 0 else 'salmon'\n",
    "        group_signature = \" \".join([str(row[col]) for col in group_cols])\n",
    "        ax.barh(group_signature, row['end'] - row['start'], left=row['start'], color=color)\n",
    "        ax.plot([row['MAE_base'], row['MAE_base']], [i-0.4, i+0.4], color='black', linewidth=2)\n",
    "\n",
    "        # Ticks\n",
    "        \n",
    "        if row['dMAE'] <= 0:\n",
    "            ax.text(row['end']-0.005, i+0.16, f'{row[\"end\"]:.2f}', va='center', ha='right', color='green', size='x-small', weight='semibold')\n",
    "            ax.text(row['end']-0.005, i-0.16, f'({row[\"dMAE\"]:.2f})', va='center', ha='right', color='green', size='x-small', weight='semibold')\n",
    "            ax.text(row['MAE_base']+0.005, i, f'{row[\"MAE_base\"]:.2f}', va='center', ha='left', color='black',  size='x-small', weight='semibold')\n",
    "        else: \n",
    "            ax.text(row['end'], i, f'{row[\"end\"]:.2f} (+{row[\"dMAE\"]:.2f})', va='center', ha='left', color='red', size='x-small', weight='semibold')\n",
    "            ax.text(row['MAE_base']-0.005, i, f'{row[\"MAE_base\"]:.2f}', va='center', ha='right', color='black',  size='x-small', weight='semibold')\n",
    "        \n",
    "\n",
    "    ax.set_yticks([]) # Remove Y-axis tick labels since we will replace them with detailed text\n",
    "    ax.set_xlim(0.60, 1.82)\n",
    "    table_text_props = {'verticalalignment': 'center', 'horizontalalignment': 'right'}\n",
    "\n",
    "    gap = -0.18\n",
    "    start = 0.58\n",
    "    x_positions = []\n",
    "    for i in range(4):\n",
    "        x_positions.append(start + gap * i)\n",
    "\n",
    "    for i in range(len(ddf)):\n",
    "        ax.text(x=x_positions[3], y=i, s=ddf.loc[i, 'SUBJECT'], **table_text_props)\n",
    "        ax.text(x=x_positions[2], y=i, s=ddf.loc[i, 'model'], **table_text_props)\n",
    "\n",
    "        ax.text(x=x_positions[1], y=i, s=ddf.loc[i, 'retrieval method'], **table_text_props)\n",
    "        ax.text(x=x_positions[0], y=i, s=format_ctx_limit(ddf.loc[i]), **table_text_props)\n",
    "\n",
    "        # ax.text(x=x_positions[0], y=i, s=\"n=3\", **table_text_props)\n",
    "        ax.axhline(y=i - 0.5, xmin=0, xmax=1, color='lightgray', linewidth=0.8)\n",
    "        \n",
    "\n",
    "    # Add table column headers\n",
    "    ax.text(x=x_positions[3], y=len(ddf), s=\"Persona\", fontweight='bold', **table_text_props)\n",
    "    ax.text(x=x_positions[2], y=len(ddf), s=\"LLM\", fontweight='bold', **table_text_props)\n",
    "\n",
    "    ax.text(x=x_positions[1], y=len(ddf), s='Method', fontweight='bold', **table_text_props)\n",
    "    ax.text(x=x_positions[0], y=len(ddf), s='Context Size', fontweight='bold', **table_text_props)\n",
    "\n",
    "    # ax.text(x=x_positions[0], y=len(ddf), s='n', fontweight='bold', **table_text_props)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Adjust the plot layout to make room for the table but with smaller gaps\n",
    "    plt.subplots_adjust(right=0.50)\n",
    "\n",
    "    lines = []\n",
    "    labels = []\n",
    "        # Adding horizontal lines for guidelines\n",
    "    if graph[\"srv\"] == 'KanoSurvey':\n",
    "        lines_new = [plt.axvline(x=0.9125, color='blue', linestyle='--')]\n",
    "        labels_new = ['Real Mean Guess for kano: 0.9125']\n",
    "    elif graph[\"srv\"] == 'PersonalitySurvey':\n",
    "        lines_new = [plt.axvline(x=1.210, color='red', linestyle='--')]\n",
    "        labels_new = ['Real Mean Guess for pers: 1.210']\n",
    "    else:\n",
    "        lines_new = [plt.axvline(x=0.9125, color='blue', linestyle='--'), plt.axhline(y=1.210, color='red', linestyle='--')]\n",
    "        labels_new = ['Real Mean Guess for Kano: 0.9125', 'Real Mean Guess for pers: 1.210']\n",
    "    \n",
    "    lines.extend(lines_new)\n",
    "    labels.extend(labels_new)\n",
    "    plt.figlegend(lines, labels, loc='upper left', ncol=2, fontsize=10)\n",
    "\n",
    "\n",
    "    # Adding labels and title\n",
    "    ax.set_xlabel('MAE')\n",
    "    ax.set_title('Change in MAE from LLM base (best configuration)')\n",
    "    super_format_ax(ax)\n",
    "    ax.set_facecolor('#f8eee0')\n",
    "\n",
    "    fig.suptitle(f\"Survey type: {graph['srv']}\", fontsize=14, x=0.26, y=1.05)\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UU ELI5 Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FuncFormatter\n",
    "import matplotlib.patches as patches\n",
    "def pp(x, decimals=0):\n",
    "    \"\"\"\n",
    "    Formats a percentage value to be displayed as a string.\n",
    "    \"\"\"\n",
    "    return f'{x*100:.{decimals}f}%'\n",
    "\n",
    "formatter = FuncFormatter(lambda x, _: pp(x, decimals=0))\n",
    "\n",
    "### Remapping\n",
    "def remap_to_simple(x, p0, p1=0):\n",
    "    return (x - p0) / (p1 - p0)\n",
    "\n",
    "# def format_survey_type(survey_type: str) -> str:\n",
    "#     if survey_type == 'KanoSurvey':\n",
    "#         return 'Kano'\n",
    "#     elif survey_type == 'PersonalitySurvey':\n",
    "#         return 'Personality'\n",
    "#     else:\n",
    "#         return survey_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global settings\n",
    "ARROW_STYLE = {\"width\":0.8, \"headwidth\":6, \"headlength\":6}\n",
    "VALUE_LABEL_STYLE = {'va': 'center', \"fontsize\":11}\n",
    "PLOT_LABELS = {\"kano\": 'Video game prefference survey\\n(using Kano Model Mapping structure)', \"pers\":'Personality survey\\n (using the Big Five personality traits)'}\n",
    "LEGEND_LABELS = {\"kano\": 'Baseline accuracy: always guessing mean', \"pers\":'Baseline accuracy: always guessing mean'}\n",
    "LEGEND_LABEL_MAX = \"Ideal accuracy: always guessing correctly\"\n",
    "\n",
    "# Get the rows with best performance (min MAE) for each group\n",
    "group_cols = ['SUBJECT', 'model', \"survey_type\"]\n",
    "dfg_nobase = dfg[dfg['is_base'] == False]\n",
    "ddbf = dfg_nobase.loc[dfg_nobase.groupby(['SUBJECT', 'model', 'survey_type'])['MAE'].idxmin()]\n",
    "\n",
    "# Graphic individualization\n",
    "graphs = [\n",
    "    {\n",
    "        \"srv\": \"KanoSurvey\",\n",
    "    },\n",
    "    {\n",
    "        \"srv\": \"PersonalitySurvey\",\n",
    "    },\n",
    "]\n",
    "\n",
    "for graph in graphs:\n",
    "    ddf = ddbf[ddbf['survey_type'] == graph[\"srv\"]].sort_values(ascending=False, by='MAE').reset_index()\n",
    "    ddf = ddf.drop(columns=[\"index\"])\n",
    "\n",
    "    ### Remapping\n",
    "    # Remaps where 1 is interpreted as the maximum accuracy, where MAE is 0, while 0 is the Naive Guess Accuracy\n",
    "    # Linearly scales between these two points.\n",
    "    p0 = global_base_scores[\"mean_guess\"][\"kano\" if graph[\"srv\"] == 'KanoSurvey' else \"pers\"]\n",
    "\n",
    "    values_to_remap = ['MAE', 'MAE_base']\n",
    "    for value_name in values_to_remap:\n",
    "        ddf[value_name] = ddf[value_name].apply(lambda x: remap_to_simple(x, p0=p0))\n",
    "\n",
    "    ddf[\"dMAE\"] = ddf[\"MAE\"] - ddf[\"MAE_base\"] # Perhaps remove. It's not needed for the simple remap\n",
    "    ###\n",
    "\n",
    "    # Calculate start and end points\n",
    "\n",
    "    ddf['start'] = ddf['MAE_base']\n",
    "    ddf['end'] = ddf['MAE']\n",
    "\n",
    "    ADD_TO_MOST_IMPORTANT_COLUMNS = [\"MAE_rm\",\"dMAE_rm\", \"start\", \"end\"]\n",
    "\n",
    "    # Create figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(18, 3))\n",
    "    # fig.patch.set_facecolor('#efdbbd')\n",
    "    # Plot each bar\n",
    "    for i, row in ddf.iterrows():\n",
    "    \n",
    "        if row['dMAE'] <= 0:\n",
    "            color = 'salmon'\n",
    "        elif  row[\"MAE\"] > 0:\n",
    "            color = 'lightgreen'\n",
    "        else:\n",
    "            color = 'lightgray'\n",
    "        # color = 'salmon' if row['dMAE'] <= 0 else 'lightgreen'\n",
    "        group_signature = \" \".join([str(row[col]) for col in group_cols])\n",
    "        ax.barh(group_signature, row['end'] - row['start'], left=row['start'], color=color)\n",
    "        ax.plot([row['MAE_base'], row['MAE_base']], [i-0.4, i+0.4], color='black', linewidth=2)\n",
    "\n",
    "        # Ticks\n",
    "        \n",
    "        if row['MAE'] < row['MAE_base']:\n",
    "            ax.text(row['end']-0.005, i+0.16, f'{pp(row[\"end\"])}', ha='right', color='red', **VALUE_LABEL_STYLE)\n",
    "            ax.text(row['end']-0.005, i-0.16, f'({pp(row[\"dMAE\"])})', ha='right', color='red', **VALUE_LABEL_STYLE)\n",
    "            ax.text(row['MAE_base']+0.01, i, f'{pp(row[\"MAE_base\"])}', ha='left', color='black', **VALUE_LABEL_STYLE)\n",
    "\n",
    "            if abs(row['dMAE']) > 0.01:\n",
    "                ax.annotate(\"\", xy=(row['MAE'], i), xytext=(row['MAE_base'], i),\n",
    "                    arrowprops=dict(**ARROW_STYLE,  color='darkred'))\n",
    "        else: \n",
    "            ax.text(row['end']+0.005, i+0.16, f'{pp(row[\"end\"])}', ha='left', color='green', **VALUE_LABEL_STYLE)\n",
    "            ax.text(row['end']+0.005, i-0.16, f'(+{pp(row[\"dMAE\"])})', ha='left', color='green', **VALUE_LABEL_STYLE)\n",
    "            ax.text(row['MAE_base']-0.005, i, f'{pp(row[\"MAE_base\"])}', ha='right', color='black', **VALUE_LABEL_STYLE)\n",
    "            if abs(row['dMAE']) > 0.025:\n",
    "                ax.annotate(\"\", xy=(row['MAE'], i), xytext=(row['MAE_base'], i),\n",
    "                    arrowprops=dict(**ARROW_STYLE,  color='darkgreen'))\n",
    "        \n",
    "\n",
    "    ax.set_yticks([]) # Remove Y-axis tick labels since we will replace them with detailed text\n",
    "    ax.set_xlim(-0.62, 1.05)\n",
    "    \n",
    "    table_text_props = {'verticalalignment': 'center', 'horizontalalignment': 'right'}\n",
    "    start = ax.get_xlim()[0] - 0.02\n",
    "\n",
    "    column_scalings = [0.75,1.4,1,1,1]\n",
    "\n",
    "\n",
    "    # Define the table functions\n",
    "    def get_offset(i, gap=-0.18):\n",
    "        # Affecs only graphcical stuff\n",
    "        # Weird and failed attempt to implement offset. Do not try to understand, it makes no sense tbh.\n",
    "        cs = column_scalings[:i]\n",
    "        offset = start\n",
    "        for scaling in cs:\n",
    "            offset  += gap * scaling\n",
    "        return offset\n",
    "    table_values = [\n",
    "        lambda idx, i: ax.text(x=get_offset(idx), y=i, s=ddf.loc[i, 'model'], weight= 'semibold', **table_text_props),\n",
    "        lambda idx, i: ax.text(x=get_offset(idx), y=i, s=\"trying to imitate\", fontstyle='italic', **table_text_props),\n",
    "        lambda idx, i: ax.text(x=get_offset(idx), y=i, s=format_subject(ddf.loc[i, 'SUBJECT']), weight= 'semibold', **table_text_props),\n",
    "        # lambda idx, i: ax.text(x=get_offset(idx), y=i, s=ddf.loc[i, 'retrieval method'], **table_text_props),\n",
    "        # lambda idx, i: ax.text(x=get_offset(idx), y=i, s=format_ctx_limit(ddf.loc[i]), **table_text_props),\n",
    "    ]\n",
    "    table_headers = [\n",
    "        lambda idx: ax.text(x=get_offset(idx), y=len(ddf), s=\"\", fontweight='bold', **table_text_props),\n",
    "        lambda idx: ax.text(x=get_offset(idx), y=len(ddf), s=\"\", fontweight='bold', **table_text_props),\n",
    "        lambda idx: ax.text(x=get_offset(idx), y=len(ddf), s=\"\", fontweight='bold', **table_text_props),\n",
    "        # lambda idx: ax.text(x=get_offset(idx), y=len(ddf), s='Method', fontweight='bold', **table_text_props),\n",
    "        # lambda idx: ax.text(x=get_offset(idx), y=len(ddf), s='Context Size', fontweight='bold', **table_text_props),\n",
    "    ]\n",
    "\n",
    "    # Add values and headers\n",
    "    for i in range(len(ddf)):\n",
    "        for i2, func in enumerate(reversed(table_values)):\n",
    "            func(i2, i)\n",
    "        ax.axhline(y=i - 0.5, xmin=0, xmax=1, color='lightgray', linewidth=0.8)\n",
    "        \n",
    "    for i, func in enumerate(reversed(table_headers)):\n",
    "        func(i)\n",
    "\n",
    "    \n",
    "    # Adjust the plot layout to make room for the table but with smaller gaps\n",
    "    plt.subplots_adjust(right=0.58, bottom=-0.13)\n",
    "\n",
    "    lines = []\n",
    "    labels = []\n",
    "\n",
    "    # Adding horizontal lines for guidelines\n",
    "    if graph[\"srv\"] == 'KanoSurvey':\n",
    "        lines_new = [plt.axvline(x=0, color='black', linestyle='-')]\n",
    "        labels_new = [LEGEND_LABELS['kano']]\n",
    "    elif graph[\"srv\"] == 'PersonalitySurvey':\n",
    "        lines_new = [plt.axvline(x=0, color='black', linestyle='-')]\n",
    "        labels_new = [LEGEND_LABELS['pers']]\n",
    "    else:\n",
    "        lines_new = [plt.axvline(x=0, color='black', linestyle='-'), plt.axhline(y=0, color='darkred', linestyle='-')]\n",
    "        labels_new = [LEGEND_LABELS['kano'], LEGEND_LABELS['pers']]\n",
    "\n",
    "    lines_new.append(plt.axvline(x=1, color='darkgreen', linestyle='--'))\n",
    "    labels_new.append(LEGEND_LABEL_MAX)\n",
    "    \n",
    "    lines.extend(lines_new)\n",
    "    labels.extend(labels_new)\n",
    "    plt.figlegend(lines, labels, loc='upper left', ncol=1, fontsize=10, bbox_to_anchor=(-0.05, 1.2))\n",
    "\n",
    "    ax.axvspan(ax.get_xlim()[0], 0, color='gray', alpha=0.12)\n",
    "    ax.axvspan(0, ax.get_xlim()[1], color='green', alpha=0.12)\n",
    "\n",
    "\n",
    "    # Adding labels and title\n",
    "    ax.set_xlabel('Accuracy')\n",
    "    ax.set_title('Change in accuracy after personalizing the LLM')\n",
    "\n",
    "    # ax.set_facecolor('#f8eee0')\n",
    "    \n",
    "    fig.suptitle(PLOT_LABELS['kano' if graph['srv'] == \"KanoSurvey\" else 'pers' ] , fontsize=14, x=0.3, y=1.15)\n",
    "\n",
    "    ax.xaxis.set_major_formatter(formatter) # Format the x-axis as percentage\n",
    "\n",
    "    # Add the area with diagonal lines (manually put with xy coords)\n",
    "    ax.add_patch(\n",
    "    patches.Rectangle(\n",
    "        xy=(0, -0.75),  # Bottom left corner of the rectangle\n",
    "        width=-10,  # width of rectangle\n",
    "        height=10,  # height of rectangle\n",
    "        fill=True,  # fill the inside of the rectangle\n",
    "        hatch='/',  # the stripe pattern\n",
    "        fc='None',  # face color\n",
    "        ec='gray', ##FF5959\n",
    "        zorder=0,\n",
    "        alpha=0.2,\n",
    "    ))\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Vanity stuff for\n",
    "for col in ADD_TO_MOST_IMPORTANT_COLUMNS:\n",
    "    if col in MOST_IMPORTANT_COLUMNS:\n",
    "        MOST_IMPORTANT_COLUMNS.remove(col)\n",
    "MOST_IMPORTANT_COLUMNS = ADD_TO_MOST_IMPORTANT_COLUMNS + MOST_IMPORTANT_COLUMNS\n",
    "ddf = utils.bring_to_front_important_columns(ddf, MOST_IMPORTANT_COLUMNS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UU Simplified Graph (Elias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming df_grouped is your existing DataFrame\n",
    "# If it's not defined, you'll need to create it or load it from somewhere\n",
    "\n",
    "# Aggregate data by SUBJECT and survey_type\n",
    "df_agg = df_grouped.groupby(['SUBJECT', 'survey_type']).agg({\n",
    "    'MAE_base': 'mean',\n",
    "    'MAE': 'mean',\n",
    "    'dMAE': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Create subplots\n",
    "# Create subplots (Vertical this time)\n",
    "fig, axes = plt.subplots(2, 1, figsize=(11, 4), sharex=True, sharey=True) \n",
    "# fig, axes = plt.subplots(1, 2, figsize=(24, 4), sharex=True, sharey=True)\n",
    "fig.patch.set_facecolor('#efdbbd')\n",
    "\n",
    "graphs = [\n",
    "    {\"srv\": \"PersonalitySurvey\", \"ax\": axes[0], \"color\": 'red'},\n",
    "    {\"srv\": \"KanoSurvey\", \"ax\": axes[1], \"color\": 'blue'}\n",
    "]\n",
    "\n",
    "for graph in graphs:\n",
    "    # Filter data for the current survey type\n",
    "    ddf = df_agg[df_agg['survey_type'] == graph[\"srv\"]].reset_index(drop=True)  # No sorting here\n",
    "\n",
    "    ddf['start'] = ddf['MAE_base']\n",
    "    ddf['end'] = ddf['MAE_base'] + ddf['dMAE']\n",
    "\n",
    "    # Plot each bar\n",
    "    for i, row in ddf.iterrows():\n",
    "        color = 'lightgreen' if row['dMAE'] <= 0 else 'salmon'\n",
    "        # Modify the subject label before passing it to graph[\"ax\"].barh()\n",
    "        subject = row['SUBJECT']\n",
    "        if subject == 'airidas':\n",
    "            subject = 'Subj-L'\n",
    "        elif subject == 'elias':\n",
    "            subject = 'Subj-S'\n",
    "        graph[\"ax\"].barh(subject, row['end'] - row['start'], left=row['start'], color=color) \n",
    "        # graph[\"ax\"].barh(row['SUBJECT'], row['end'] - row['start'], left=row['start'], color=color)\n",
    "        graph[\"ax\"].plot([row['MAE_base'], row['MAE_base']], [i-0.4, i+0.4], color='black', linewidth=2)\n",
    "\n",
    "\n",
    "    graph[\"ax\"].set_xlim(0.60, 1.82)#0.80, 1.35)\n",
    "    # graph[\"ax\"].set_xlabel('MAE')\n",
    "    graph[\"ax\"].set_title(f'dMAE$_B$$_a$$_s$$_e$ - {graph[\"srv\"]}')\n",
    "    graph[\"ax\"].set_facecolor('#f8eee0')\n",
    "\n",
    "    # Add Real Mean Guess line\n",
    "    mean_guess = 0.9125 if graph[\"srv\"] == 'KanoSurvey' else 1.210\n",
    "    graph[\"ax\"].axvline(x=mean_guess, color=graph[\"color\"], linestyle='--', label=f'MAE$_G$$_u$$_e$$_s$$_s$: {mean_guess}') #{graph[\"srv\"]}\n",
    "    \n",
    "    graph[\"ax\"].legend(loc='upper right', fontsize=10)\n",
    "\n",
    "# Adjust layout and show plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UU Simplified Graph (New)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global settings\n",
    "ARROW_STYLE = {\"width\":0.8, \"headwidth\":6, \"headlength\":6}\n",
    "VALUE_LABEL_STYLE = {'va': 'center', \"fontsize\":11}\n",
    "PLOT_LABELS = {\"kano\": 'Kano video game survey', \"pers\":'OCEAN survey'}\n",
    "\n",
    "# Aggregation logic\n",
    "aggregations = {}\n",
    "for column, dtype in dfg.dtypes.items():\n",
    "    if dtype in ['int64', 'float64']:  # Add other numeric types if needed\n",
    "        aggregations[column] = 'mean'\n",
    "    else:\n",
    "        aggregations[column] = various_or_single\n",
    "\n",
    "# Get the rows with best performance (min MAE) for each group\n",
    "group_cols = ['SUBJECT', 'survey_type']\n",
    "dfg_nobase = dfg[dfg['is_base'] == False]\n",
    "# ddbf = dfg_nobase.loc[dfg_nobase.groupby(['SUBJECT', 'model', 'survey_type'])['MAE'].idxmin()]\n",
    "\n",
    "ddbf = dfg_nobase.groupby(group_cols).agg(aggregations).drop(columns=group_cols).reset_index()\n",
    "\n",
    "# Graphic individualization\n",
    "graphs = [\n",
    "    {\n",
    "        \"srv\": \"KanoSurvey\",\n",
    "    },\n",
    "    {\n",
    "        \"srv\": \"PersonalitySurvey\",\n",
    "    },\n",
    "]\n",
    "\n",
    "for graph in graphs:\n",
    "    fig, ax = plt.subplots(figsize=(18, 1.3))\n",
    "\n",
    "    ddf = ddbf[ddbf['survey_type'] == graph[\"srv\"]].sort_values(ascending=False, by='MAE').reset_index()\n",
    "    ddf = ddf.drop(columns=[\"index\"])\n",
    "\n",
    "    # Calculate start and end points\n",
    "    ddf['start'] = ddf['MAE_base']\n",
    "    ddf['end'] = ddf['MAE']\n",
    "\n",
    "\n",
    "    ############################ FOR EACH BAR ############################\n",
    "    for i, row in ddf.iterrows():\n",
    "    \n",
    "        if row['dMAE'] <= 0:\n",
    "            color = 'lightgreen'\n",
    "        elif  row[\"MAE\"] > 0:\n",
    "            color = 'salmon'\n",
    "        else:\n",
    "            color = 'lightgray'\n",
    "        \n",
    "        group_signature = \" \".join([str(row[col]) for col in group_cols])\n",
    "        ax.barh(group_signature, row['end'] - row['start'], left=row['start'], color=color)\n",
    "        ax.plot([row['MAE_base'], row['MAE_base']], [i-0.4, i+0.4], color='black', linewidth=2)\n",
    "\n",
    "        # VALUE ANNOTATIONS\n",
    "        if row['MAE'] < row['MAE_base']:\n",
    "            ax.text(row['end']-0.005, i+0.16, f'{row[\"end\"]:.2f}', ha='right', color='green', **VALUE_LABEL_STYLE)\n",
    "            ax.text(row['end']-0.005, i-0.16, f'({row[\"dMAE\"]:.2f})', ha='right', color='green', **VALUE_LABEL_STYLE)\n",
    "            ax.text(row['MAE_base']+0.01, i, f'{row[\"MAE_base\"]:.2f}', ha='left', color='black', **VALUE_LABEL_STYLE)\n",
    "\n",
    "            if abs(row['dMAE']) > 0.01:\n",
    "                ax.annotate(\"\", xy=(row['MAE'], i), xytext=(row['MAE_base'], i),\n",
    "                    arrowprops=dict(**ARROW_STYLE,  color='darkgreen'))\n",
    "        else: \n",
    "            ax.text(row['end']+0.005, i+0.16, f'{row[\"end\"]:.2f}', ha='left', color='red', **VALUE_LABEL_STYLE)\n",
    "            ax.text(row['end']+0.005, i-0.16, f'(+{row[\"dMAE\"]:.2f})', ha='left', color='red', **VALUE_LABEL_STYLE)\n",
    "            ax.text(row['MAE_base']-0.005, i, f'{row[\"MAE_base\"]:.2f}', ha='right', color='black', **VALUE_LABEL_STYLE)\n",
    "            if abs(row['dMAE']) > 0.025:\n",
    "                ax.annotate(\"\", xy=(row['MAE'], i), xytext=(row['MAE_base'], i),\n",
    "                    arrowprops=dict(**ARROW_STYLE,  color='darkred'))\n",
    "\n",
    "    ############################ TICKS ############################\n",
    "    ax.set_yticks([]) # Remove Y-axis tick labels since we will replace them with detailed text\n",
    "    ax.set_xlim(0, 1.50)\n",
    "    \n",
    "    table_text_props = {'verticalalignment': 'center', 'horizontalalignment': 'right'}\n",
    "    start = ax.get_xlim()[0] - 0.02\n",
    "\n",
    "    \n",
    "\n",
    "    ############################ LEFT LABELS (TABLE-LIKE) ############################\n",
    "    column_scalings = [0.75,1.4,1,1,1]\n",
    "    def get_offset(i, gap=-0.18):\n",
    "        # Affecs only graphcical stuff\n",
    "        # Weird and failed attempt to implement offset. Do not try to understand, it makes no sense tbh.\n",
    "        cs = column_scalings[:i]\n",
    "        offset = start\n",
    "        for scaling in cs:\n",
    "            offset  += gap * scaling\n",
    "        return offset\n",
    "    \n",
    "    table_values = [\n",
    "        # lambda idx, i: ax.text(x=get_offset(idx), y=i, s=ddf.loc[i, 'model'], weight= 'semibold', **table_text_props),\n",
    "        # lambda idx, i: ax.text(x=get_offset(idx), y=i, s=\"trying to imitate\", fontstyle='italic', **table_text_props),\n",
    "        lambda idx, i: ax.text(x=get_offset(idx), y=i, s=anonymize_subject(ddf.loc[i, 'SUBJECT']), weight= 'semibold', **table_text_props),\n",
    "        # lambda idx, i: ax.text(x=get_offset(idx), y=i, s=ddf.loc[i, 'retrieval method'], **table_text_props),\n",
    "        # lambda idx, i: ax.text(x=get_offset(idx), y=i, s=format_ctx_limit(ddf.loc[i]), **table_text_props),\n",
    "    ]\n",
    "    table_headers = [\n",
    "        # lambda idx: ax.text(x=get_offset(idx), y=len(ddf), s=\"\", fontweight='bold', **table_text_props),\n",
    "        # lambda idx: ax.text(x=get_offset(idx), y=len(ddf), s=\"\", fontweight='bold', **table_text_props),\n",
    "        lambda idx: ax.text(x=get_offset(idx), y=len(ddf), s=\"\", fontweight='bold', **table_text_props),\n",
    "        # lambda idx: ax.text(x=get_offset(idx), y=len(ddf), s='Method', fontweight='bold', **table_text_props),\n",
    "        # lambda idx: ax.text(x=get_offset(idx), y=len(ddf), s='Context Size', fontweight='bold', **table_text_props),\n",
    "    ]\n",
    "\n",
    "    # Add values and headers\n",
    "    for i in range(len(ddf)):\n",
    "        for i2, func in enumerate(reversed(table_values)):\n",
    "            func(i2, i)\n",
    "        ax.axhline(y=i - 0.5, xmin=0, xmax=1, color='lightgray', linewidth=0.8)\n",
    "        \n",
    "    for i, func in enumerate(reversed(table_headers)):\n",
    "        func(i)\n",
    "\n",
    "    ############################ RANDOM SHIT ############################\n",
    "    # Adjust the plot layout to make room for the table but with smaller gaps\n",
    "    plt.subplots_adjust(right=0.58, bottom=-0.13)\n",
    "\n",
    "\n",
    "    ############################ LINES ############################\n",
    "    lines = []\n",
    "    labels = []\n",
    "\n",
    "    # Adding horizontal lines for guidelines and calc worse_than_middle_guess_xy\n",
    "    if graph[\"srv\"] == 'KanoSurvey':\n",
    "        mean_guess = 0.9125\n",
    "        labels_new = [f'MAE$_G$$_u$$_e$$_s$$_s$: {mean_guess}']\n",
    "    elif graph[\"srv\"] == 'PersonalitySurvey':\n",
    "        mean_guess = 1.210\n",
    "        labels_new = [f'MAE$_G$$_u$$_e$$_s$$_s$: {mean_guess}']\n",
    "    else:\n",
    "        raise Exception(\"This code should not be reached\")\n",
    "    \n",
    "    lines_new = [plt.axvline(x=mean_guess, color='black', linestyle='--')]\n",
    "    worse_than_middle_guess_xy = (mean_guess, -0.75)\n",
    "    \n",
    "\n",
    "    # Adds a custom line\n",
    "    # lines_new.append(plt.axvline(x=1, color='darkgreen', linestyle='--'))\n",
    "    # labels_new.append(LEGEND_LABEL_MAX)\n",
    "    \n",
    "    lines.extend(lines_new)\n",
    "    labels.extend(labels_new)\n",
    "    plt.figlegend(lines, labels, loc='upper right', ncol=1, fontsize=10, bbox_to_anchor=(0.585, 1.2)) # numbers are pure fiddling. Idk how to automate\n",
    "\n",
    "    ax.axvspan(worse_than_middle_guess_xy[0], ax.get_xlim()[1], color='gray', alpha=0.12)\n",
    "    ax.axvspan(0, worse_than_middle_guess_xy[0], color='green', alpha=0.12)\n",
    "\n",
    "    ############################ AXES LABELS AND TITLES ############################\n",
    "    ax.set_xlabel('MAE')\n",
    "    # ax.set_title('Change in MAE after personalizing the LLM', fontsize=10)\n",
    "    ax.set_title(f'MAE$_B$$_a$$_s$$_e$ - {\"Kano video game survey\" if graph[\"srv\"] == \"KanoSurvey\" else \"OCEAN survey\"}', fontsize=12)\n",
    "    # fig.suptitle(PLOT_LABELS['kano' if graph['srv'] == \"KanoSurvey\" else 'pers' ] , fontsize=14, x=0.35, y=1.25) # numbers are pure fiddling. Idk how to automate\n",
    "    # ax.set_facecolor('#f8eee0')\n",
    "\n",
    "    ############################ DIAGONAL LINES AREA ############################\n",
    "    # for worse_than_middle_guess\n",
    "    ax.add_patch(\n",
    "    patches.Rectangle(\n",
    "        xy=worse_than_middle_guess_xy,  # Bottom left corner of the rectangle\n",
    "        width=10,  # width of rectangle\n",
    "        height=10,  # height of rectangle\n",
    "        fill=True,  # fill the inside of the rectangle\n",
    "        hatch='/',  # the stripe pattern\n",
    "        fc='None',  # face color\n",
    "        ec='gray', ##FF5959\n",
    "        zorder=0,\n",
    "        alpha=0.2,\n",
    "    ))\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Vanity stuff for debugging\n",
    "for col in ADD_TO_MOST_IMPORTANT_COLUMNS:\n",
    "    if col in MOST_IMPORTANT_COLUMNS:\n",
    "        MOST_IMPORTANT_COLUMNS.remove(col)\n",
    "MOST_IMPORTANT_COLUMNS = ADD_TO_MOST_IMPORTANT_COLUMNS + MOST_IMPORTANT_COLUMNS\n",
    "ddf = utils.bring_to_front_important_columns(ddf, MOST_IMPORTANT_COLUMNS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UU Detailed LVL1 Graph (New)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global settings\n",
    "ARROW_STYLE = {\"width\":0.8, \"headwidth\":6, \"headlength\":6}\n",
    "VALUE_LABEL_STYLE = {'va': 'center', \"fontsize\":11}\n",
    "PLOT_LABELS = {\"kano\": 'Kano video game survey', \"pers\":'OCEAN survey'}\n",
    "\n",
    "# Aggregation logic\n",
    "aggregations = {}\n",
    "for column, dtype in dfg.dtypes.items():\n",
    "    if dtype in ['int64', 'float64']:  # Add other numeric types if needed\n",
    "        aggregations[column] = 'mean'\n",
    "    else:\n",
    "        aggregations[column] = various_or_single\n",
    "\n",
    "# Get the rows with best performance (min MAE) for each group\n",
    "group_cols = ['SUBJECT', 'survey_type', 'model']\n",
    "dfg_nobase = dfg[dfg['is_base'] == False]\n",
    "# ddbf = dfg_nobase.loc[dfg_nobase.groupby(['SUBJECT', 'model', 'survey_type'])['MAE'].idxmin()]\n",
    "\n",
    "ddbf = dfg_nobase.groupby(group_cols).agg(aggregations).drop(columns=group_cols).reset_index()\n",
    "\n",
    "# Graphic individualization\n",
    "graphs = [\n",
    "    {\n",
    "        \"srv\": \"KanoSurvey\",\n",
    "    },\n",
    "    {\n",
    "        \"srv\": \"PersonalitySurvey\",\n",
    "    },\n",
    "]\n",
    "\n",
    "for graph in graphs:\n",
    "    fig, ax = plt.subplots(figsize=(18, 2.8))\n",
    "\n",
    "    ddf = ddbf[ddbf['survey_type'] == graph[\"srv\"]].sort_values(ascending=False, by='MAE').reset_index()\n",
    "    ddf = ddf.drop(columns=[\"index\"])\n",
    "\n",
    "    # Calculate start and end points\n",
    "    ddf['start'] = ddf['MAE_base']\n",
    "    ddf['end'] = ddf['MAE']\n",
    "\n",
    "\n",
    "    ############################ FOR EACH BAR ############################\n",
    "    for i, row in ddf.iterrows():\n",
    "    \n",
    "        if row['dMAE'] <= 0:\n",
    "            color = 'lightgreen'\n",
    "        elif  row[\"MAE\"] > 0:\n",
    "            color = 'salmon'\n",
    "        else:\n",
    "            color = 'lightgray'\n",
    "        \n",
    "        group_signature = \" \".join([str(row[col]) for col in group_cols])\n",
    "        ax.barh(group_signature, row['end'] - row['start'], left=row['start'], color=color)\n",
    "        ax.plot([row['MAE_base'], row['MAE_base']], [i-0.4, i+0.4], color='black', linewidth=2)\n",
    "\n",
    "        # VALUE ANNOTATIONS\n",
    "        if row['MAE'] < row['MAE_base']:\n",
    "            ax.text(row['end']-0.005, i+0.16, f'{row[\"end\"]:.2f}', ha='right', color='green', **VALUE_LABEL_STYLE)\n",
    "            ax.text(row['end']-0.005, i-0.16, f'({row[\"dMAE\"]:.2f})', ha='right', color='green', **VALUE_LABEL_STYLE)\n",
    "            ax.text(row['MAE_base']+0.01, i, f'{row[\"MAE_base\"]:.2f}', ha='left', color='black', **VALUE_LABEL_STYLE)\n",
    "\n",
    "            if abs(row['dMAE']) > 0.01:\n",
    "                ax.annotate(\"\", xy=(row['MAE'], i), xytext=(row['MAE_base'], i),\n",
    "                    arrowprops=dict(**ARROW_STYLE,  color='darkgreen'))\n",
    "        else: \n",
    "            ax.text(row['end']+0.005, i+0.16, f'{row[\"end\"]:.2f}', ha='left', color='red', **VALUE_LABEL_STYLE)\n",
    "            ax.text(row['end']+0.005, i-0.16, f'(+{row[\"dMAE\"]:.2f})', ha='left', color='red', **VALUE_LABEL_STYLE)\n",
    "            ax.text(row['MAE_base']-0.005, i, f'{row[\"MAE_base\"]:.2f}', ha='right', color='black', **VALUE_LABEL_STYLE)\n",
    "            if abs(row['dMAE']) > 0.025:\n",
    "                ax.annotate(\"\", xy=(row['MAE'], i), xytext=(row['MAE_base'], i),\n",
    "                    arrowprops=dict(**ARROW_STYLE,  color='darkred'))\n",
    "\n",
    "    ############################ TICKS ############################\n",
    "    ax.set_yticks([]) # Remove Y-axis tick labels since we will replace them with detailed text\n",
    "    ax.set_xlim(0, 2)\n",
    "    \n",
    "    table_text_props = {'verticalalignment': 'center', 'horizontalalignment': 'right'}\n",
    "    start = ax.get_xlim()[0] - 0.02\n",
    "\n",
    "    \n",
    "\n",
    "    ############################ LEFT LABELS (TABLE-LIKE) ############################\n",
    "    column_scalings = [0.95,1.1,1,1,1]\n",
    "    def get_offset(i, gap=-0.18):\n",
    "        # Affecs only graphcical stuff\n",
    "        # Weird and failed attempt to implement offset. Do not try to understand, it makes no sense tbh.\n",
    "        cs = column_scalings[:i]\n",
    "        offset = start\n",
    "        for scaling in cs:\n",
    "            offset  += gap * scaling\n",
    "        return offset\n",
    "    \n",
    "    table_values = [\n",
    "        lambda idx, i: ax.text(x=get_offset(idx), y=i, s=ddf.loc[i, 'model'], **table_text_props),\n",
    "        # lambda idx, i: ax.text(x=get_offset(idx), y=i, s=\"trying to imitate\", fontstyle='italic', **table_text_props),\n",
    "        lambda idx, i: ax.text(x=get_offset(idx), y=i, s=anonymize_subject(ddf.loc[i, 'SUBJECT']), **table_text_props),\n",
    "        # lambda idx, i: ax.text(x=get_offset(idx), y=i, s=ddf.loc[i, 'retrieval method'], **table_text_props),\n",
    "        # lambda idx, i: ax.text(x=get_offset(idx), y=i, s=format_ctx_limit(ddf.loc[i]), **table_text_props),\n",
    "    ]\n",
    "    table_headers = [\n",
    "        lambda idx: ax.text(x=get_offset(idx), y=len(ddf), s=\"LLM\", fontweight='bold', **table_text_props),\n",
    "        # lambda idx: ax.text(x=get_offset(idx), y=len(ddf), s=\"\", fontweight='bold', **table_text_props),\n",
    "        lambda idx: ax.text(x=get_offset(idx), y=len(ddf), s=\"Subject\", fontweight='bold', **table_text_props),\n",
    "        # lambda idx: ax.text(x=get_offset(idx), y=len(ddf), s='Method', fontweight='bold', **table_text_props),\n",
    "        # lambda idx: ax.text(x=get_offset(idx), y=len(ddf), s='Context Size', fontweight='bold', **table_text_props),\n",
    "    ]\n",
    "\n",
    "    # Add values and headers\n",
    "    for i in range(len(ddf)):\n",
    "        for i2, func in enumerate(reversed(table_values)):\n",
    "            func(i2, i)\n",
    "        ax.axhline(y=i - 0.5, xmin=0, xmax=1, color='lightgray', linewidth=0.8)\n",
    "        \n",
    "    for i, func in enumerate(reversed(table_headers)):\n",
    "        func(i)\n",
    "\n",
    "    ############################ RANDOM SHIT ############################\n",
    "    # Adjust the plot layout to make room for the table but with smaller gaps\n",
    "    plt.subplots_adjust(right=0.58, bottom=-0.13)\n",
    "\n",
    "\n",
    "    ############################ LINES ############################\n",
    "    lines = []\n",
    "    labels = []\n",
    "\n",
    "    # Adding horizontal lines for guidelines and calc worse_than_middle_guess_xy\n",
    "    if graph[\"srv\"] == 'KanoSurvey':\n",
    "        mean_guess = 0.9125\n",
    "        labels_new = [f'MAE$_G$$_u$$_e$$_s$$_s$: {mean_guess}']\n",
    "    elif graph[\"srv\"] == 'PersonalitySurvey':\n",
    "        mean_guess = 1.210\n",
    "        labels_new = [f'MAE$_G$$_u$$_e$$_s$$_s$: {mean_guess}']\n",
    "    else:\n",
    "        raise Exception(\"This code should not be reached\")\n",
    "    \n",
    "    lines_new = [plt.axvline(x=mean_guess, color='black', linestyle='--')]\n",
    "    worse_than_middle_guess_xy = (mean_guess, -0.75)\n",
    "    \n",
    "\n",
    "    # Adds a custom line\n",
    "    # lines_new.append(plt.axvline(x=1, color='darkgreen', linestyle='--'))\n",
    "    # labels_new.append(LEGEND_LABEL_MAX)\n",
    "    \n",
    "    lines.extend(lines_new)\n",
    "    labels.extend(labels_new)\n",
    "    plt.figlegend(lines, labels, loc='upper right', ncol=1, fontsize=10, bbox_to_anchor=(0.585, 1.05)) # numbers are pure fiddling. Idk how to automate\n",
    "\n",
    "    ax.axvspan(worse_than_middle_guess_xy[0], ax.get_xlim()[1], color='gray', alpha=0.12)\n",
    "    ax.axvspan(0, worse_than_middle_guess_xy[0], color='green', alpha=0.12)\n",
    "\n",
    "    ############################ AXES LABELS AND TITLES ############################\n",
    "    ax.set_xlabel('MAE')\n",
    "    # ax.set_title('Change in MAE after personalizing the LLM', fontsize=10)\n",
    "    ax.set_title(f'MAE$_B$$_a$$_s$$_e$ - {\"Kano video game survey\" if graph[\"srv\"] == \"KanoSurvey\" else \"OCEAN survey\"}', fontsize=12)\n",
    "    # fig.suptitle(PLOT_LABELS['kano' if graph['srv'] == \"KanoSurvey\" else 'pers' ] , fontsize=14, x=0.35, y=1.25) # numbers are pure fiddling. Idk how to automate\n",
    "    # ax.set_facecolor('#f8eee0')\n",
    "\n",
    "    ############################ DIAGONAL LINES AREA ############################\n",
    "    # for worse_than_middle_guess\n",
    "    ax.add_patch(\n",
    "    patches.Rectangle(\n",
    "        xy=worse_than_middle_guess_xy,  # Bottom left corner of the rectangle\n",
    "        width=10,  # width of rectangle\n",
    "        height=10,  # height of rectangle\n",
    "        fill=True,  # fill the inside of the rectangle\n",
    "        hatch='/',  # the stripe pattern\n",
    "        fc='None',  # face color\n",
    "        ec='gray', ##FF5959\n",
    "        zorder=0,\n",
    "        alpha=0.2,\n",
    "    ))\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Vanity stuff for debugging\n",
    "for col in ADD_TO_MOST_IMPORTANT_COLUMNS:\n",
    "    if col in MOST_IMPORTANT_COLUMNS:\n",
    "        MOST_IMPORTANT_COLUMNS.remove(col)\n",
    "MOST_IMPORTANT_COLUMNS = ADD_TO_MOST_IMPORTANT_COLUMNS + MOST_IMPORTANT_COLUMNS\n",
    "ddf = utils.bring_to_front_important_columns(ddf, MOST_IMPORTANT_COLUMNS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_del = [\n",
    "    \"col\",\n",
    "    \"a\",\n",
    "    \"ax\",\n",
    "    \"axs\",\n",
    "    \"bars\",\n",
    "    \"bar\",\n",
    "    'ddf',\n",
    "    'df_filtered',\n",
    "    'bar_value',\n",
    "    'bars',\n",
    "    'bars_len',\n",
    "    'bars_start',\n",
    "    'base_dfg',\n",
    "    'base_name',\n",
    "    'base_sign',\n",
    "    'base_val',\n",
    "    'dfQA',\n",
    "    'dfQAs_kano',\n",
    "    'dfQAs_kano_base',\n",
    "    'dfQAs_pers',\n",
    "    'dfQAs_pers_base',\n",
    "    'df_filtered',\n",
    "    'df_group',\n",
    "    'df_group_70b',\n",
    "    'df_group_8b',\n",
    "    'df_group_8x22b',\n",
    "    'df_grouped',\n",
    "    'df_plot',\n",
    "    'dff',\n",
    "    'invalid_vals',\n",
    "    'k',\n",
    "    'key',\n",
    "    'gs',\n",
    "    'grouped_data',\n",
    "    'models',\n",
    "    'mode',\n",
    "    'mins',\n",
    "    'min_value',\n",
    "    'metric_column',\n",
    "    'average_value',\n",
    "    'color',\n",
    "    \"colors\",\n",
    "    'column',\n",
    "    'corr',\n",
    "    'data',\n",
    "    'data_rounded',\n",
    "    \"dfff\",\n",
    "    'dirs',\n",
    "    'dtype',\n",
    "    'fig',\n",
    "    'file',\n",
    "    'files',\n",
    "    'gap',\n",
    "    'graph',\n",
    "    'graphs',\n",
    "    'info',\n",
    "    'labels',\n",
    "    'labels_new',\n",
    "    'line1',\n",
    "    'line2',\n",
    "]\n",
    "\n",
    "for a in to_del:\n",
    "    if a in locals():\n",
    "        del locals()[a]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlate: Airi vs Eli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surv_kano = survey.KanoSurvey()\n",
    "surv_pers = survey.PersonalitySurvey()\n",
    "\n",
    "surv_kano.df = remap_answers_to_integers(surv_kano.df, surv_kano, remap_answer=False)\n",
    "surv_pers.df = remap_answers_to_integers(surv_pers.df, surv_pers, remap_answer=False)\n",
    "\n",
    "print(f'Kano {utils.calc_MAE(surv_kano.df[\"airidas\"], surv_kano.df[\"elias\"])}')\n",
    "print(f'Pers {utils.calc_MAE(surv_pers.df[\"airidas\"], surv_pers.df[\"elias\"])}')\n",
    "# now calc pearson correlation\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "# get correlation\n",
    "corr, _ = pearsonr(surv_kano.df[\"airidas\"], surv_kano.df[\"elias\"])\n",
    "print(f'Pearsons correlation Kano: {corr}')\n",
    "corr, _ = pearsonr(surv_pers.df[\"airidas\"], surv_pers.df[\"elias\"])\n",
    "print(f'Pearsons correlation Pers: {corr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Unknown code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'mean_residual_Airidas_mean' and 'p-corr_Airidas_mean' are already computed as mean values in your aggregated dataframe\n",
    "# Plotting for Airidas\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(dfg['p-corr_Airidas_mean'], dfg['MAE_airi_mean'], label='Airidas', alpha=0.5)\n",
    "\n",
    "# Assuming 'mean_residual_Elias_mean' and 'p-corr_Elias_mean' are also computed as mean values\n",
    "# Plotting for Elias\n",
    "plt.scatter(dfg['p-corr_Elias_mean'], dfg['MAE_eli_mean'], color='red', label='Elias', alpha=0.5)\n",
    "\n",
    "plt.title('Mean Residuals vs P-Corr')\n",
    "plt.xlabel('P-Corr (mean)')\n",
    "plt.ylabel('Mean Residuals (mean)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from scipy.integrate import quad\n",
    "\n",
    "# Parameters for the normal distribution\n",
    "mu = 2  # example mean\n",
    "sigma = 1  # example standard deviation\n",
    "\n",
    "# Define the integrand function\n",
    "def integrand(x):\n",
    "    return np.abs(x - 2) * norm.pdf(x, mu, sigma)\n",
    "\n",
    "# Compute the integral\n",
    "result, _ = quad(integrand, -np.inf, np.inf)\n",
    "print(\"Mean Absolute Error:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Some mathematical proof...*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "mu, n = 2, 100000\n",
    "sigma = np.sqrt(0.9)\n",
    "np.random.seed(0)\n",
    "data = np.random.normal(mu, sigma, n)\n",
    "data_rounded = np.round(data).clip(0, 4)\n",
    "plt.figure(figsize=(4, 3))\n",
    "plt.hist(data_rounded, bins=np.arange(6) - 0.5, edgecolor='black', color='skyblue')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(range(5))\n",
    "stats_text = f\"Mean: {np.mean(data_rounded)}\\nMedian: {np.median(data_rounded)}\\nMin: {np.min(data_rounded)}\\nMax: {np.max(data_rounded)}\\nUnique Values: {len(np.unique(data_rounded))}\"\n",
    "guess = 2\n",
    "mae = np.mean(np.abs(data_rounded - guess))\n",
    "stats_text += f\"\\nMean Absolute Error (MAE) when always guessing {guess}: {mae}\"\n",
    "plt.text(5, plt.ylim()[1] * 0.95, stats_text, fontsize=8, verticalalignment='top')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
